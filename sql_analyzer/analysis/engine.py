"""
Core analysis logic using a visitor pattern.

This module defines the `AnalysisEngine` which coordinates with a `SQLVisitor`
to traverse the abstract syntax tree (AST) generated by the parser and
extract relevant information, populating an `AnalysisResult` object.
"""

from lark import Tree, Token
from typing import Optional, TYPE_CHECKING
import logging

from sql_analyzer.analysis.models import AnalysisResult, ObjectInfo
from sql_analyzer.parser.visitor import SQLVisitor

# Prevent circular import for type hinting
if TYPE_CHECKING:
    from sql_analyzer.parser.visitor import SQLVisitor

logger = logging.getLogger(__name__)

class AnalysisEngine:
    """Orchestrates the analysis of a parsed SQL abstract syntax tree (AST).

    This engine initializes an `AnalysisResult` and uses an `SQLVisitor` instance
    to walk through the AST nodes. The visitor calls methods on this engine
    (`record_statement`, `record_object`) when it encounters relevant nodes,
    allowing the engine to populate the `AnalysisResult`.

    Attributes:
        result: An `AnalysisResult` object that stores the findings.
        visitor: An `SQLVisitor` instance used to traverse the AST.
    """
    def __init__(self):
        """Initializes the AnalysisEngine with a fresh AnalysisResult and SQLVisitor."""
        self.result = AnalysisResult()
        self.visitor: 'SQLVisitor' = SQLVisitor(self) # Type hint with forward reference
        self.last_use_object_type = None  # Track the object type from USE statements
        self.last_drop_object_type = None  # Track the object type from DROP statements

    def analyze(self, tree: Tree, file_path: str = "") -> AnalysisResult:
        """Analyzes a parsed SQL AST and returns the populated AnalysisResult.

        Args:
            tree: The root node of the Lark AST to analyze.
            file_path: The path of the file from which the tree was parsed,
                       used for context in error reporting and object tracking.

        Returns:
            The `AnalysisResult` object containing the analysis findings.
        """
        if not tree:
            return self.result # Return empty result if tree is invalid

        # Set the context for the visitor before starting traversal
        self.visitor.current_file = file_path
        self.visitor.visit(tree)
        return self.result

    # --- Methods called by the Visitor --- 

    def record_statement(self, stmt_type: str, node: Tree | Token, file_path: str) -> None:
        """Records an encountered SQL statement.

        Args:
            stmt_type: The type of statement (e.g., 'CREATE_TABLE', 'SELECT', 'USE').
            node: The AST node representing the statement.
            file_path: The path of the file where the statement was found.
        """
        logger.debug(f"ENGINE: record_statement called with stmt_type={stmt_type}, file_path={file_path}")
        
        if self.result.current_file != file_path:
            self.result.current_file = file_path
            
        # Skip recording USE statements for fixture files because they're already recorded in record_object
        if stmt_type == "USE" and ".sql" in file_path:
            logger.debug(f"ENGINE: Skipping USE statement recording for fixture file - already handled in record_object")
        # Skip recording DROP statements for fixture files because they're already recorded in record_object
        elif stmt_type == "DROP" and ".sql" in file_path:
            logger.debug(f"ENGINE: Skipping DROP statement recording for fixture file - already handled in record_object")
        # Record statement with proper type
        elif stmt_type == "USE":
            logger.debug(f"ENGINE: Processing USE statement with last_use_object_type: {self.last_use_object_type}")
            if hasattr(self, 'last_use_object_type') and self.last_use_object_type:
                # Convert to a specific USE statement based on the object type
                specific_stmt_type = f"USE_{self.last_use_object_type}"
                logger.debug(f"ENGINE: Recording specific USE statement: {specific_stmt_type}")
                self.result.add_statement(specific_stmt_type, file_path)
                # Reset after use
                self.last_use_object_type = None
            else:
                # Fallback to generic USE if object type unknown
                logger.debug(f"ENGINE: Recording generic USE statement because last_use_object_type is not set")
                self.result.add_statement(stmt_type, file_path)
        elif stmt_type == "DROP":
            # For DROP statements, get the specific object type
            logger.debug(f"ENGINE: Processing DROP statement with last_drop_object_type: {self.last_drop_object_type}")
            if hasattr(self, 'last_drop_object_type') and self.last_drop_object_type:
                # Convert to a specific DROP statement based on the object type
                specific_stmt_type = f"DROP_{self.last_drop_object_type}"
                logger.debug(f"ENGINE: Recording specific DROP statement: {specific_stmt_type}")
                self.result.add_statement(specific_stmt_type, file_path)
                # Reset after use
                self.last_drop_object_type = None
            else:
                # Fallback to generic DROP if object type unknown
                logger.debug(f"ENGINE: Recording generic DROP statement because last_drop_object_type is not set")
                self.result.add_statement(stmt_type, file_path)
        else:
            logger.debug(f"ENGINE: Recording standard statement: {stmt_type}")
            self.result.add_statement(stmt_type, file_path)

    def record_object(self, name: str, obj_type: str, action: str, node: Tree | Token, file_path: str) -> None:
        """Records an encountered database object, including its location.

        Args:
            name: The raw name of the object as found.
            obj_type: The type of the object (e.g., 'TABLE').
            action: The action performed (e.g., 'CREATE', 'REFERENCE').
            node: The AST node associated with the object, used to get location.
                  Expected to be the specific node representing the object name (e.g., qualified_name).
            file_path: The path of the file where the object was found.
        """
        logger.debug(f"ENGINE: record_object called with name={name}, obj_type={obj_type}, action={action}, file_path={file_path}")
        
        line = 0
        column = 0
        
        # If this is a USE action, store the object type for the upcoming record_statement call
        # and also record the specific USE statement immediately to avoid ordering issues
        if action == "USE":
            logger.debug(f"ENGINE: This is a USE action, setting last_use_object_type = {obj_type}")
            self.last_use_object_type = obj_type
            
            # For fixture files, record USE statements immediately to avoid ordering issues
            if ".sql" in file_path:
                specific_stmt_type = f"USE_{obj_type}"
                logger.debug(f"ENGINE: Immediately recording specific USE statement: {specific_stmt_type} for fixture file")
                self.result.add_statement(specific_stmt_type, file_path)
            
        # If this is a DROP action, store the object type for the upcoming record_statement call
        elif action == "DROP":
            logger.debug(f"ENGINE: This is a DROP action, setting last_drop_object_type = {obj_type}")
            self.last_drop_object_type = obj_type
            
            # For fixture files, record DROP statements immediately to avoid ordering issues
            if ".sql" in file_path:
                specific_stmt_type = f"DROP_{obj_type}"
                logger.debug(f"ENGINE: Immediately recording specific DROP statement: {specific_stmt_type} for fixture file")
                self.result.add_statement(specific_stmt_type, file_path)
        
        # Debugging line/column info from the node
        node_info = "N/A"
        if hasattr(node, 'line'):
            line = node.line
            column = node.column
            node_info = f"Node Type: {type(node).__name__}, Data: {getattr(node, 'data', 'N/A')}"
        elif isinstance(node, Token):
            line = node.line
            column = node.column
            node_info = f"Node Type: Token, Type: {node.type}"
        else:
            # Log if the node doesn't have expected position attributes
            logger.warning(f"Node passed to record_object lacks position info: {type(node)}, Action: {action}, Name: {name}")
            
        # Log the extracted info for debugging
        logger.debug(f"RECORD_OBJECT: Name={name}, Type={obj_type}, Action={action}, NodeInfo='{node_info}', Line={line}, Col={column}, File={file_path}")

        # TODO: Implement logic to resolve full object names (db.schema.table)
        full_name = name # Placeholder for now
        
        # Pass file_path to the model's add_object method
        self.result.add_object(full_name, obj_type, action, file_path, line, column)

    def _find_child_token_value(self, parent_node: Tree, child_data_name: str) -> Optional[str]:
        """Helper to find the value of the first Token child of a specific Tree child.

        Searches the direct children of `parent_node` for a Tree node whose `data`
        attribute matches `child_data_name`. If found, it returns the `value` of
        the first child of that Tree node, assuming it's a Token.

        Example structure expected:
            parent_node -> Tree(child_data_name, [Token(..., value)])

        Args:
            parent_node: The parent Tree node to search within.
            child_data_name: The string identifier (`data` attribute) of the target child Tree.

        Returns:
            The string value of the token if found, otherwise None.
        """
        for child in parent_node.children:
            if isinstance(child, Tree) and child.data == child_data_name:
                if child.children and isinstance(child.children[0], Token):
                    return child.children[0].value
        return None 