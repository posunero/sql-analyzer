"""
Lark Visitor for traversing the SQL Abstract Syntax Tree (AST).

This visitor identifies specific statement types (e.g., SELECT, CREATE TABLE)
and database objects (e.g., tables, views, databases) within the AST generated
by the Lark parser. It collaborates with the `AnalysisEngine` to record these findings.
"""

from lark import Visitor, Tree, Token
from typing import List, Dict, Any, TYPE_CHECKING, Optional
import logging

if TYPE_CHECKING:
    from sql_analyzer.analysis.engine import AnalysisEngine

logger = logging.getLogger(__name__) # Module-level logger

# List of destructive statement types to track
DESTRUCTIVE_STATEMENTS = {
    'DELETE', 'DROP_TABLE', 'DROP_VIEW', 'DROP_DATABASE', 'DROP_SCHEMA', 
    'DROP_TASK', 'TRUNCATE_TABLE', 'TRUNCATE', 'CREATE_OR_REPLACE_TABLE', 'CREATE_OR_REPLACE_VIEW',
    'ALTER_TABLE_DROP_COLUMN', 'UPDATE', 'DROP', 'DROP_SHARE', 'DROP_INTEGRATION',
    'DROP_EXTERNAL_TABLE', 'DROP_MATERIALIZED_VIEW', 'DROP_EXTERNAL_FUNCTION',
    # Add specific replacements
    'REPLACE'
}

class SQLVisitor(Visitor[Token]): # Inherit from Visitor[Token] for better type hinting
    """Traverses the SQL AST generated by Lark to identify statements and objects.

    It extracts information about statement types and database object references,
    calling methods on the provided `AnalysisEngine` instance to record the findings.

    Attributes:
        engine: An instance of `AnalysisEngine` to record findings.
        current_file: The path of the file currently being processed.
    """
    
    def __init__(self, engine: 'AnalysisEngine'):
        """Initializes the visitor with a reference to the analysis engine."""
        self.engine: 'AnalysisEngine' = engine
        self.current_file: str = ""
        self.debug = False  # Set to True to enable debug output
        
    def _debug(self, msg):
        """Print debug message if debug mode is enabled."""
        if self.debug:
            print(msg)
            
    def _debug_tree(self, tree: Tree | Token, prefix: str = "Node") -> None:
        """Logs the structure of a Tree or Token node for debugging if log level is DEBUG.

        Args:
            tree: The Lark Tree or Token to log.
            prefix: A string prefix for the log message.
        """
        if logger.isEnabledFor(logging.DEBUG):
            def _format_node(node: Tree | Token | Any, indent: int = 0) -> str:
                indent_str = "  " * indent
                if isinstance(node, Tree):
                    children_str = "".join([_format_node(child, indent + 1) for child in node.children])
                    return f"{indent_str}{node.data}\n{children_str}"
                elif isinstance(node, Token):
                    # Escape potential newlines in token values for cleaner logging
                    value_repr = repr(node.value)
                    return f"{indent_str}TOKEN[{node.type}]: {value_repr}\n"
                else:
                    return f"{indent_str}OTHER: {node}\n"

            tree_dump = _format_node(tree).rstrip() # Remove trailing newline
            logger.debug(f"\n--- {prefix} (File: {self.current_file}) ---\n{tree_dump}\n-------------------\n")

    def _find_first_child_by_name(self, tree: Tree, name: str) -> Optional[Tree]:
        """Find the first direct child Tree node with the given `data` attribute name.

        Args:
            tree: The parent Tree node whose children to search.
            name: The `data` attribute value to look for in child Tree nodes.

        Returns:
            The first matching child Tree node, or None if not found.
        """
        if not isinstance(tree, Tree):
            return None
        for child in tree.children:
            if isinstance(child, Tree) and hasattr(child, 'data') and child.data == name:
                return child
        return None

    def _extract_qualified_name(self, tree: Tree) -> Optional[str]:
        """Extract the full name (dot-separated identifiers) from a `qualified_name` node.

        Assumes the input `tree` has a `data` attribute equal to 'qualified_name'
        and contains child Tokens of type 'IDENTIFIER'.

        Args:
            tree: The Tree node representing the qualified name.

        Returns:
            A dot-separated string of the identifiers, or None if extraction fails.
        """
        if not isinstance(tree, Tree) or not hasattr(tree, 'data') or tree.data != 'qualified_name':
            logger.warning(f"_extract_qualified_name called on non-qualified_name node: {getattr(tree, 'data', type(tree))}")
            return None

        name_parts = [
            child.value for child in tree.children
            if isinstance(child, Token) and child.type == 'IDENTIFIER'
        ]

        if not name_parts:
            logger.warning(f"No IDENTIFIER tokens found in qualified_name node: {tree}")
            return None

        return ".".join(name_parts)

    def _record_table_reference_in_context(self, table_name: str, action: str, node: Tree | Token) -> None:
        """Record a table reference within the current context (e.g., task).

        If we're processing within a task context, record the dependency between
        the task and the referenced table.

        Args:
            table_name: The name of the referenced table
            action: The action being performed (e.g., 'REFERENCE', 'INSERT', 'UPDATE')
            node: The AST node that contains the table reference
        """
        # First, record the standard object reference
        self.engine.record_object(
            name=table_name,
            obj_type="TABLE",
            action=action,
            node=node,
            file_path=self.current_file
        )
        
        # If we're in a task context, record the dependency between the task and the table
        context = getattr(self, 'current_context', None)
        if context and context['type'] == 'TASK' and context['name']:
            # Record the dependency with the appropriate relationship type based on the action
            relationship_type = action  # Use action as relationship type by default
            self.engine.result.add_dependency(
                "TASK", context['name'],
                "TABLE", table_name,
                relationship_type
            )

    def _record_object_reference(self, obj_name: str, obj_type: str, action: str, node: Tree | Token) -> None:
        """Record an object reference with the correct object type.

        Args:
            obj_name: The name of the referenced object
            obj_type: The type of the object (e.g., 'TABLE', 'STAGE', 'FILE_FORMAT', 'WAREHOUSE')
            action: The action being performed (e.g., 'REFERENCE', 'CREATE', 'DROP')
            node: The AST node that contains the object reference
        """
        # Record the standard object reference with the specified type
        self.engine.record_object(
            name=obj_name,
            obj_type=obj_type,
            action=action,
            node=node,
            file_path=self.current_file
        )
        
        # If we're within a context (e.g., TASK or PIPE), record the dependency between the parent and the object
        context = getattr(self, 'current_context', None)
        if context and context.get('name'):
            parent_type = context.get('type')
            relationship_type = action
            self.engine.result.add_dependency(
                parent_type, context.get('name'),
                obj_type, obj_name,
                relationship_type
            )

    def statement(self, tree: Tree):
        """Intercepts high-level `statement` nodes.

        Delegates the recording of the specific statement type (e.g., SELECT,
        CREATE_TABLE) to the AnalysisEngine, which handles the necessary refinement.
        Lark automatically proceeds to visit the specific statement child node afterwards.
        """
        self._debug_tree(tree, "Statement")
        
        # --- Determine the specific statement node and its type ---
        specific_stmt_node = None
        raw_node_data = None # The '.data' attribute of the specific stmt node

        if tree.children and isinstance(tree.children[0], Tree):
            specific_stmt_node = tree.children[0]
            raw_node_data = specific_stmt_node.data.upper()

            # Special handling for DML/DDL wrappers
            if raw_node_data == 'DML_STMT' and isinstance(specific_stmt_node.children[0], Tree):
                specific_stmt_node = specific_stmt_node.children[0]
                raw_node_data = specific_stmt_node.data.upper()
            elif raw_node_data == 'DDL_STMT' and isinstance(specific_stmt_node.children[0], Tree):
                 ddl_child_node = specific_stmt_node.children[0]
                 ddl_child_type = ddl_child_node.data.upper()
                 
                 # If it's a CREATE, ALTER, or DROP statement, look one more level
                 if ddl_child_type in ('CREATE_STMT', 'ALTER_STMT', 'DROP_STMT') and ddl_child_node.children:
                     if isinstance(ddl_child_node.children[0], Tree):
                         final_stmt_node = ddl_child_node.children[0]
                         final_node_data = final_stmt_node.data.upper()

                         # Check for CREATE OR REPLACE patterns - PREFER this if found
                         is_replace = any(isinstance(child, Token) and child.type == 'REPLACE' for child in final_stmt_node.children)
                         if final_node_data.startswith('CREATE_') and is_replace:
                             object_type = final_node_data.replace('CREATE_', '').replace('_STMT', '')
                             raw_node_data = f'CREATE_OR_REPLACE_{object_type}'
                             specific_stmt_node = final_stmt_node # Point to the actual node
                         else:
                            raw_node_data = final_node_data
                            specific_stmt_node = final_stmt_node
                     else: # e.g., DROP ROLE <name>; might have ROLE token instead of Tree
                         raw_node_data = ddl_child_type # Use CREATE/ALTER/DROP_STMT
                         specific_stmt_node = ddl_child_node
                 else:
                     # Use the DDL child type directly (e.g., TRUNCATE_TABLE_STMT)
                     raw_node_data = ddl_child_type
                     specific_stmt_node = ddl_child_node

        if not specific_stmt_node or not raw_node_data:
             logger.warning(f"Unexpected structure for statement node: {tree.pretty()}")
             self.visit_children(tree) # Still visit children
             return

        # --- Map grammar node type to canonical statement type ---
        stmt_type_mapping = {
            # DML
            'SELECT_STMT': 'SELECT',
            'UPDATE_STMT': 'UPDATE',
            'INSERT_STMT': 'INSERT',
            'DELETE_STMT': 'DELETE',
            'MERGE_STMT': 'MERGE',
            'TRUNCATE_TABLE_STMT': 'TRUNCATE_TABLE', # Often considered DDL but acts like DML
            'TRUNCATE_STMT': 'TRUNCATE', # Generic truncate if grammar has it

            # DDL - Create
            'CREATE_TABLE_STMT': 'CREATE_TABLE',
            'CREATE_VIEW_STMT': 'CREATE_VIEW',
            'CREATE_DATABASE_STMT': 'CREATE_DATABASE',
            'CREATE_SCHEMA_STMT': 'CREATE_SCHEMA',
            'CREATE_STAGE_STMT': 'CREATE_STAGE',
            'CREATE_FILE_FORMAT_STMT': 'CREATE_FILE_FORMAT',
            'CREATE_FUNCTION_STMT': 'CREATE_FUNCTION',
            'CREATE_TASK_STMT': 'CREATE_TASK',
            'CREATE_JOB_STMT': 'CREATE_JOB', # Assuming JOB exists
            'CREATE_INTEGRATION_STMT': 'CREATE_INTEGRATION',
            'CREATE_EXTERNAL_TABLE_STMT': 'CREATE_EXTERNAL_TABLE',
            'CREATE_MATERIALIZED_VIEW_STMT': 'CREATE_MATERIALIZED_VIEW',
            'CREATE_EXTERNAL_FUNCTION_STMT': 'CREATE_EXTERNAL_FUNCTION',
            'CREATE_NETWORK_POLICY_STMT': 'CREATE_NETWORK_POLICY',
            'CREATE_REPLICATION_STMT': 'CREATE_REPLICATION',
            'CREATE_ACCOUNT_STMT': 'CREATE_ACCOUNT',
            'CREATE_ROW_ACCESS_POLICY_STMT': 'CREATE_ROW_ACCESS_POLICY',
            'CREATE_MASKING_POLICY_STMT': 'CREATE_MASKING_POLICY',
            'CREATE_ALERT_STMT': 'CREATE_ALERT',
            'CREATE_ICEBERG_TABLE_STMT': 'CREATE_ICEBERG_TABLE',
            'CREATE_PACKAGE_STMT': 'CREATE_PACKAGE',
            'CREATE_AUTHENTICATION_POLICY_STMT': 'CREATE_AUTHENTICATION_POLICY',
            'CREATE_RESOURCE_MONITOR_STMT': 'CREATE_RESOURCE_MONITOR',
            'CREATE_ROLE_STMT': 'CREATE_ROLE',
            'CREATE_SHARE_STMT': 'CREATE_SHARE',
            'CREATE_STREAM_STMT': 'CREATE_STREAM',
            'CREATE_PIPE_STMT': 'CREATE_PIPE',

            # DDL - Create or Replace (Use raw_node_data directly for these)
            'CREATE_OR_REPLACE_TABLE': 'CREATE_OR_REPLACE_TABLE',
            'CREATE_OR_REPLACE_VIEW': 'CREATE_OR_REPLACE_VIEW',
            'CREATE_OR_REPLACE_TASK': 'CREATE_TASK', # Map CREATE_OR_REPLACE_TASK back to CREATE_TASK for counting? Or keep separate? Let's map for now.
            # Add other CREATE_OR_REPLACE types if needed, ensuring raw_node_data handles them

            # DDL - Alter
            'ALTER_TABLE_STMT': 'ALTER_TABLE',
            'ALTER_VIEW_STMT': 'ALTER_VIEW', # If exists
            'ALTER_DATABASE_STMT': 'ALTER_DATABASE', # If exists
            'ALTER_SCHEMA_STMT': 'ALTER_SCHEMA', # If exists
            'ALTER_WAREHOUSE_STMT': 'ALTER_WAREHOUSE',
            'ALTER_TASK_STMT': 'ALTER_TASK',
            'ALTER_JOB_STMT': 'ALTER_JOB', # If exists
            'ALTER_SESSION_STMT': 'ALTER_SESSION',
            'ALTER_INTEGRATION_STMT': 'ALTER_INTEGRATION',
            'ALTER_EXTERNAL_TABLE_STMT': 'ALTER_EXTERNAL_TABLE',
            'ALTER_MATERIALIZED_VIEW_STMT': 'ALTER_MATERIALIZED_VIEW',
            'ALTER_EXTERNAL_FUNCTION_STMT': 'ALTER_EXTERNAL_FUNCTION',
            'ALTER_NETWORK_POLICY_STMT': 'ALTER_NETWORK_POLICY',
            'ALTER_REPLICATION_STMT': 'ALTER_REPLICATION',
            'ALTER_ACCOUNT_STMT': 'ALTER_ACCOUNT',
            'ALTER_STAGE_STMT': 'ALTER_STAGE',
            'ALTER_ROW_ACCESS_POLICY_STMT': 'ALTER_ROW_ACCESS_POLICY',
            'ALTER_ALERT_STMT': 'ALTER_ALERT',
            'ALTER_ICEBERG_TABLE_STMT': 'ALTER_ICEBERG_TABLE',
            'ALTER_AUTHENTICATION_POLICY_STMT': 'ALTER_AUTHENTICATION_POLICY',
            'ALTER_SHARE_STMT': 'ALTER_SHARE',
            'ALTER_STREAM_STMT': 'ALTER_STREAM',
            'ALTER_PIPE_STMT': 'ALTER_PIPE',

            # DDL - Drop
            'DROP_TABLE_STMT': 'DROP_TABLE',
            'DROP_VIEW_STMT': 'DROP_VIEW',
            'DROP_DATABASE_STMT': 'DROP_DATABASE',
            'DROP_SCHEMA_STMT': 'DROP_SCHEMA',
            'DROP_TASK_STMT': 'DROP_TASK',
            'DROP_INTEGRATION_STMT': 'DROP_INTEGRATION',
            'DROP_EXTERNAL_TABLE_STMT': 'DROP_EXTERNAL_TABLE',
            'DROP_MATERIALIZED_VIEW_STMT': 'DROP_MATERIALIZED_VIEW',
            'DROP_EXTERNAL_FUNCTION_STMT': 'DROP_EXTERNAL_FUNCTION',
            'DROP_NETWORK_POLICY_STMT': 'DROP_NETWORK_POLICY',
            'DROP_ACCOUNT_STMT': 'DROP_ACCOUNT',
            'DROP_SHARE_STMT': 'DROP_SHARE',
            'DROP_STMT': 'DROP', # Generic DROP needs refinement in drop_stmt visitor

            # DCL
            'GRANT_ROLE_STMT': 'GRANT_ROLE',
            'REVOKE_ROLE_STMT': 'REVOKE_ROLE',

            # TCL
            'BEGIN_STMT': 'BEGIN',
            'COMMIT_STMT': 'COMMIT',
            'ROLLBACK_STMT': 'ROLLBACK',
            'SAVEPOINT_STMT': 'SAVEPOINT',
            'ROLLBACK_TO_SAVEPOINT_STMT': 'ROLLBACK_TO_SAVEPOINT',

            # Session/Scripting
            'USE_STMT': 'USE', # Refined in use_stmt visitor
            'DECLARE_STMT': 'DECLARE',
            'SET_STMT': 'SET',
            'EXECUTE_IMMEDIATE_STMT': 'EXECUTE_IMMEDIATE',
            'EXECUTE_TASK_STMT': 'EXECUTE_TASK',
            'CALL_PROCEDURE_STMT': 'CALL',

            # Stage/File Ops
            'COPY_INTO_STMT': 'COPY_INTO', # Base type, specific types recorded elsewhere
            'PUT_STMT': 'PUT',
            'GET_STMT': 'GET_STAGE',
            'LIST_STMT': 'LIST_STAGE',
            'REMOVE_STMT': 'REMOVE_STAGE',

            # Other
            'SHOW_STMT': 'SHOW', # Needs refinement based on object type shown
            'DESCRIBE_STMT': 'DESCRIBE', # Needs refinement
            'SHOW_ACCOUNTS_STMT': 'SHOW_ACCOUNTS',
            'SHOW_PARAMETERS_STMT': 'SHOW_PARAMETERS',
            'INSTALL_PACKAGE_STMT': 'INSTALL_PACKAGE',
            'REMOVE_PACKAGE_STMT': 'REMOVE_PACKAGE',
            'ENABLE_SEARCH_OPTIMIZATION_STMT': 'ENABLE_SEARCH_OPTIMIZATION',
            'DISABLE_SEARCH_OPTIMIZATION_STMT': 'DISABLE_SEARCH_OPTIMIZATION',
            'ALTER_SEARCH_OPTIMIZATION_STMT': 'ALTER_SEARCH_OPTIMIZATION',
            
            # Add mappings derived from SIMPLE_QN_METHODS if not covered above
            # (This ensures consistency if a node exists in both places)
            **{method_details[0].upper(): method_details[2] for method_details in SQLVisitor.SIMPLE_QN_METHODS}
        }

        # Get the mapped statement type or use the original node data if not found
        stmt_type = stmt_type_mapping.get(raw_node_data, raw_node_data)
        logger.debug(f"Statement raw node data: '{raw_node_data}' -> mapped stmt_type: '{stmt_type}'")

        # --- Record Statement Count (ONLY if no dedicated visitor exists) ---
        # Heuristic: Check if a method exists in the visitor matching the raw node name
        # (e.g., 'create_table_stmt' method for 'CREATE_TABLE_STMT' node)
        # Convert raw_node_data (like CREATE_TABLE_STMT) to expected method name format (create_table_stmt)
        expected_method_name = raw_node_data.lower()

        # Check against known dedicated methods (more reliable than just endswith('_stmt'))
        # Use the sets defined earlier (assuming they are available in this scope or passed/recalculated)
        # Placeholder for actual implementation:
        # dedicated_visitor_node_uppers = self._get_dedicated_visitor_nodes() # Assume this method exists

        # TEMPORARY HARDCODED LIST FOR DEMONSTRATION - REPLACE WITH DYNAMIC CHECK
        # This set should contain the *Lark node data names* (UPPERCASE) that have dedicated visitors.
        _nodes_with_dedicated_visitors_upper = {
            'SELECT_STMT', 'INSERT_STMT', 'CREATE_TABLE_STMT', 'ALTER_TABLE_STMT',
            'CREATE_VIEW_STMT', 'CREATE_DATABASE_STMT', 'ALTER_WAREHOUSE_STMT',
            'UPDATE_STMT', 'DROP_STMT', 'USE_STMT', 'CREATE_FUNCTION_STMT',
            'FUNCTION_CALL', 'DELETE_STMT', 'TRUNCATE_TABLE_STMT', 'TRUNCATE_STMT', 
            'CREATE_STAGE_STMT', 'CREATE_FILE_FORMAT_STMT', 'COPY_INTO_STMT',
            'CREATE_STREAM_STMT', 'ALTER_STREAM_STMT', 'CREATE_PIPE_STMT',
            'ALTER_PIPE_STMT', 'ENABLE_SEARCH_OPTIMIZATION_STMT',
            'DISABLE_SEARCH_OPTIMIZATION_STMT', 'ALTER_SEARCH_OPTIMIZATION_STMT',
            'GRANT_ROLE_STMT', 'REVOKE_ROLE_STMT', 'CREATE_ROLE_STMT',
            'CREATE_JOB_STMT', 'ALTER_JOB_STMT', 'CREATE_TASK_STMT',
            'ALTER_TASK_STMT', 'MERGE_STMT', 
            'ALTER_TABLE_SET_MASKING_POLICY_STMT', # Explicit method name doesn't end in _stmt
            'EXECUTE_TASK_STMT', 'CALL_PROCEDURE_STMT', 'CREATE_SCHEMA_STMT',
            # Add nodes corresponding to SIMPLE_QN_METHODS
            *[m[0].upper() for m in SQLVisitor.SIMPLE_QN_METHODS]
        }
        
        # Record statement count in the *generic* visitor only if there isn't a specific one
        if raw_node_data not in _nodes_with_dedicated_visitors_upper:
             logger.debug(f"Recording statement count '{stmt_type}' from generic 'statement' visitor (no dedicated visitor for '{raw_node_data}').")
             self.engine.record_statement(stmt_type, specific_stmt_node, self.current_file)
        else:
             logger.debug(f"Skipping statement count for '{stmt_type}' in generic 'statement' visitor (dedicated visitor exists for '{raw_node_data}').")

        # --- Record Destructive Statement ---
        # Check the *mapped* stmt_type against the destructive list
        # Let dedicated visitors handle their specific destructive counts (e.g., DROP_TABLE in drop_stmt)
        # Only record generic ones like UPDATE, DELETE here.
        if stmt_type in DESTRUCTIVE_STATEMENTS and not stmt_type.startswith("DROP_") and stmt_type != "CREATE_OR_REPLACE_TABLE" and stmt_type != "CREATE_OR_REPLACE_VIEW":
            logger.debug(f"Recording destructive statement '{stmt_type}' from generic 'statement' visitor.")
            self.engine.record_destructive_statement(stmt_type, specific_stmt_node, self.current_file)

        # --- Proceed with visiting the specific statement node ---
        # Lark's default behavior handles this - *no need* for explicit self.visit(specific_stmt_node) here
        # self.visit(specific_stmt_node) # DO NOT UNCOMMENT - Lark handles descent automatically

    def select_stmt(self, tree: Tree):
        """Visits `select_stmt` nodes. Extracts table references from the `from_clause`.

        Identifies tables/views referenced in FROM and JOIN clauses.
        Records found objects as 'SELECT' for object interactions.
        Then, manually visits other children (like select_list) to find nested objects.
        """
        self._debug_tree(tree, "Select Statement")
        # Record the SELECT statement count
        self.engine.record_statement("SELECT", tree, self.current_file)
        
        from_clause = self._find_first_child_by_name(tree, 'from_clause')
        
        # --- Process FROM and JOIN first --- 
        if from_clause:
            # Helper to record a table/view/stage reference
            def record_ref(node: Tree):
                qual_name_node = self._find_first_child_by_name(node, 'qualified_name')
                stage_path_node = self._find_first_child_by_name(node, 'STAGE_PATH')

                ref_name = None
                obj_type = None
                first_token = None

                if qual_name_node:
                    ref_name = self._extract_qualified_name(qual_name_node)
                    first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
                elif stage_path_node:
                    ref_name = stage_path_node.children[0].value if stage_path_node.children else ""
                    first_token = stage_path_node # Use the node itself for location
                
                if not ref_name or not first_token:
                    return # Could not extract name or location info

                # *** Determine object type based on name prefix ***
                if ref_name.startswith('@'):
                    obj_type = "STAGE"
                else:
                    obj_type = "TABLE" # Assume TABLE/VIEW for non-@ names

                # Check if the parent (base_table_ref) has an alias sibling
                is_alias = False
                if hasattr(node, 'parent') and node.parent is not None:
                    siblings = node.parent.children
                    try:
                        node_index = siblings.index(node)
                        if node_index + 1 < len(siblings):
                            next_sibling = siblings[node_index + 1]
                            if isinstance(next_sibling, Token) and next_sibling.type == 'IDENTIFIER':
                                if node_index + 2 >= len(siblings) or not (isinstance(siblings[node_index + 2], Token) and siblings[node_index + 2].type == 'DOT'):
                                    is_alias = True 
                            if node_index > 0 and isinstance(siblings[node_index -1], Token) and siblings[node_index - 1].type == 'AS':
                                is_alias = True
                    except ValueError:
                        pass 
                                
                common_aliases = {"regionsales", "topcustomers", "cte1", "sub"} 
                if isinstance(ref_name, str) and ref_name.lower() in common_aliases:
                    logger.debug(f"Skipping likely alias: {ref_name}")
                    return
                
                if isinstance(ref_name, str) and ref_name.lower() in {"for"}: 
                    logger.debug(f"Skipping likely keyword: {ref_name}")
                    return

                logger.debug(f"Found {obj_type} reference in SELECT/JOIN: {ref_name}")
                # Record as REFERENCE
                self._record_object_reference(ref_name, obj_type, "REFERENCE", first_token)
                
                # Also record as SELECT for object interactions (only if it's a TABLE)
                if obj_type == "TABLE":
                     self._record_object_reference(ref_name, obj_type, "SELECT", first_token)

            # Record base table references excluding function table refs
            for node in from_clause.find_data('base_table_ref'):
                if not self._find_first_child_by_name(node, 'function_call'):
                    record_ref(node)

            # Record joined table references excluding function table refs
            for join_node in from_clause.find_data('join_clause'):
                join_table_node = self._find_first_child_by_name(join_node, 'base_table_ref')
                if join_table_node and not self._find_first_child_by_name(join_table_node, 'function_call'):
                    record_ref(join_table_node)
        # --- END Process FROM and JOIN --- 

        # --- Manually visit other children (like select_list, where_clause) --- 
        for child in tree.children:
            # Avoid re-visiting the from_clause we already processed
            if child is not from_clause:
                 # Only visit if it's a Tree, skip Tokens
                 if isinstance(child, Tree):
                     self.visit(child)
        # --- END Manual visit --- 

    def insert_stmt(self, tree: Tree):
        """Visits `insert_stmt` nodes. Extracts the target `qualified_name`.

        Records the found table as 'REFERENCE' for backward compatibility,
        and as 'INSERT' for object interactions.
        Assumes the first qualified_name after INSERT INTO is the target.
        """
        self._debug_tree(tree, "Insert Statement")
        # Find the first qualified_name, which should be the target table
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            table_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found table reference in INSERT: {table_name}")
                # Record in the current context (e.g., task context)
                self._record_object_reference(table_name, "TABLE", "INSERT", first_token)
        # Recurse into nested SQL (SELECT, VALUES, etc.) to capture dependencies
        for child in tree.children:
            if isinstance(child, Tree):
                self.visit(child)

    def create_table_stmt(self, tree: Tree):
        """Visits `create_table_stmt` nodes. Extracts the `qualified_name` of the table.

        Records the found table as \'CREATE\' or as \'REPLACE\' if it\'s a CREATE OR REPLACE statement.
        Also ensures CREATE OR REPLACE is tracked as a destructive operation.
        """
        self._debug_tree(tree, "Create Table Statement")
        table_name = None
        first_token = None
        action = "CREATE_TABLE" # Default action for statement count

        # Check if this is a CREATE OR REPLACE statement
        is_replace = any(isinstance(child, Token) and child.type == 'REPLACE' for child in tree.children)

        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            table_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if table_name and first_token:
                # Determine action for object recording vs statement counting
                obj_action = "REPLACE" if is_replace else "CREATE"
                action = "CREATE_OR_REPLACE_TABLE" if is_replace else "CREATE_TABLE"

                logger.debug(f"Found table {obj_action}: {table_name} (Stmt Action: {action})")
                self._record_object_reference(table_name, "TABLE", obj_action, first_token)

                # Record the specific statement count
                self.engine.record_statement(action, tree, self.current_file) # ADDED

                # If it's a REPLACE operation, record as destructive
                if is_replace:
                    self.engine.record_destructive_statement("CREATE_OR_REPLACE_TABLE", tree, self.current_file)
            else:
                logger.warning(f"Create Table: Failed to extract name/token from {qual_name_node.pretty()}")
                # Attempt to record statement count even if object recording fails
                self.engine.record_statement(action, tree, self.current_file)

        # Added: record CLONE source tables
        for clone in tree.find_data('clone_clause'):
            # Extract qualified_name node within the clone clause
            qual_name_node = self._find_first_child_by_name(clone, 'qualified_name')
            if qual_name_node:
                source = self._extract_qualified_name(qual_name_node)
                # Use first identifier token for location
                tok = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
                if source and tok:
                    self._record_object_reference(source, 'TABLE', 'CLONE', tok)
            # Ensure statement count happens even with CLONE (should occur above)

    def alter_table_stmt(self, tree: Tree):
        """Visits `alter_table_stmt` nodes. Identifies table alterations.

        Checks for DROP COLUMN operations specifically, and records them as such.
        Records the table being altered and any columns being dropped.
        """
        self._debug_tree(tree, "Alter Table Statement (Generic)")
        # First find the table being altered
        table_ref = self._find_first_child_by_name(tree, 'qualified_name')
        table_name = None
        first_token = None # Token for the table name

        if table_ref:
            table_name = self._extract_qualified_name(table_ref)
            first_token = next((t for t in table_ref.children if isinstance(t, Token)), None)
            if table_name and first_token:
                # Record the basic ALTER action on the table
                self._record_object_reference(table_name, "TABLE", "ALTER", first_token)
                # Record the ALTER_TABLE statement
                self.engine.record_statement("ALTER_TABLE", tree, self.current_file)
            # Statement count for ALTER_TABLE handled by specific visitors or _handle_simple_qn_stmt if applicable
            # Or potentially in the main 'statement' visitor if no specific handler matches.

        # Check for DROP COLUMN operations - using a more flexible approach
        is_drop_column = False
        column_name = None
        drop_column_token_location = None # Token to use for recording location of drop

        # Look for a DROP token followed by a COLUMN token anywhere in the statement
        drop_token_index = None
        for i, child in enumerate(tree.children):
            if isinstance(child, Token) and child.type == 'DROP':
                drop_token_index = i
                break

        if drop_token_index is not None and drop_token_index + 1 < len(tree.children):
            # Check if the next token is COLUMN
            next_token = tree.children[drop_token_index + 1]
            if isinstance(next_token, Token) and next_token.type == 'COLUMN':
                is_drop_column = True
                drop_column_token_location = next_token # Use COLUMN token location

                # Try to get column name (usually the next token after COLUMN)
                if drop_token_index + 2 < len(tree.children):
                    column_token = tree.children[drop_token_index + 2]
                    if isinstance(column_token, Token):
                        column_name = column_token.value
                        # Potentially update location token to the column name itself
                        # drop_column_token_location = column_token

        # Also look for a possible 'drop_column_clause' node which might be present in some grammars
        drop_column_node = None
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'drop_column_clause':
                drop_column_node = child
                is_drop_column = True
                # Use the node itself or its first token for location
                drop_column_token_location = next((t for t in child.scan_values(lambda v: isinstance(v, Token))), child)
                # Try to extract column name
                for subchild in child.children:
                    if isinstance(subchild, Token) and subchild.type == 'IDENTIFIER':
                        column_name = subchild.value
                        # Update location token if preferred
                        # drop_column_token_location = subchild
                        break
                break

        if is_drop_column and table_name:
            # Use a valid token for recording (column drop location, or table token as fallback)
            record_token = drop_column_token_location if isinstance(drop_column_token_location, Token) else first_token
            if record_token:
                # Record the DROP_COLUMN action and the column name if found
                action = "DROP_COLUMN"
                if column_name:
                    logger.debug(f"Found DROP COLUMN operation on {table_name}.{column_name}")
                    # Record specific column drop
                    # Note: Recording "TABLE" type here might be debatable, could be "COLUMN"
                    # Let's stick to TABLE for consistency with previous logic unless tests require COLUMN
                    self._record_object_reference(f"{table_name}.{column_name}", "TABLE", action, record_token)

                    # Also record DROP_COLUMN action on the table itself for easier querying
                    self._record_object_reference(table_name, "TABLE", action, record_token)

                    # Always record that this is a destructive action
                    self.engine.record_destructive_statement("ALTER_TABLE_DROP_COLUMN", tree, self.current_file)
                    # Statement count for ALTER_TABLE_DROP_COLUMN? Handled by simple qn? Let's assume so.
                else:
                    logger.debug(f"Found DROP COLUMN operation on {table_name} but couldn't identify column name")
                    # Still record as destructive even if we can't identify the column
                    self._record_object_reference(table_name, "TABLE", action, record_token)
                    self.engine.record_destructive_statement("ALTER_TABLE_DROP_COLUMN", tree, self.current_file)
            else:
                 logger.warning(f"ALTER TABLE DROP COLUMN on {table_name}: Could not determine a valid location token.")

        # Recurse into specific ALTER TABLE actions like MODIFY COLUMN
        for child in tree.children:
            if isinstance(child, Tree):
                # Check for common alter column clause names (adjust if grammar differs)
                if child.data in ('modify_column_clause', 'alter_column_clause', 'column_alteration', 'alter_table_set_masking_policy_stmt'):
                    # Pass the table context down to the specific clause visitor
                    # Store table_name and token on the child node temporarily, or pass via context
                    # Using context is cleaner if multiple clauses need it
                    old_context = getattr(self, 'current_context', None)
                    self.current_context = {
                        'type': 'ALTER_TABLE',
                        'table_name': table_name,
                        'table_token': first_token
                    }
                    try:
                        self.visit(child) # Visit the specific clause node
                    finally:
                        self.current_context = old_context
                # Add other clause visits if needed (e.g., ADD COLUMN)
                # elif child.data == 'add_column_clause':
                #     self.visit(child)

    def create_view_stmt(self, tree: Tree):
        """Visits `create_view_stmt` nodes. Extracts the `qualified_name` of the view.

        Records the found view as \'CREATE\' or as \'REPLACE\' if it\'s a CREATE OR REPLACE statement.
        Also ensures CREATE OR REPLACE is tracked as a destructive operation.
        The underlying SELECT statement (and its references) are visited automatically by Lark.
        """
        # The underlying SELECT statement (and its references) will be visited automatically.
        self._debug_tree(tree, "Create View Statement")
        view_name = None
        first_token = None
        action = "CREATE_VIEW" # Default action name

        # Check if this is a CREATE OR REPLACE statement
        is_replace = any(isinstance(child, Token) and child.type == 'REPLACE' for child in tree.children)

        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            view_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if view_name and first_token:
                # Determine action for object recording vs statement counting
                obj_action = "REPLACE" if is_replace else "CREATE"
                action = "CREATE_OR_REPLACE_VIEW" if is_replace else "CREATE_VIEW"

                logger.debug(f"Found view {obj_action}: {view_name} (Stmt Action: {action})")
                self._record_object_reference(view_name, "VIEW", obj_action, first_token)
                # Record the statement count - Handled by statement visitor logic or specific if needed
                # self.engine.record_statement(action, tree, self.current_file) # Let generic handler do it

                # If it's a REPLACE operation, record as destructive
                if is_replace:
                    self.engine.record_destructive_statement("CREATE_OR_REPLACE_VIEW", tree, self.current_file)
            else:
                 logger.warning(f"Create View: Failed to extract name or token from {qual_name_node.pretty()}")
                 # self.engine.record_statement(action, tree, self.current_file)

        # No need to manually visit children, Lark handles the SELECT statement visit.

    def create_database_stmt(self, tree: Tree):
        """Visits `create_database_stmt` nodes. Extracts the `qualified_name` of the database.

        Records the found database as \'CREATE\'.
        """
        self._debug_tree(tree, "Create Database Statement")
        db_name = None
        first_token = None
        action = "CREATE_DATABASE" # Default action name for statement count

        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            db_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if db_name and first_token:
                # Check for OR REPLACE
                is_replace = any(isinstance(child, Token) and child.type == 'REPLACE' for child in tree.children)
                obj_action = "CREATE_OR_REPLACE_DATABASE" if is_replace else "CREATE" # For object map
                action = "CREATE_OR_REPLACE_DATABASE" if is_replace else "CREATE_DATABASE" # For statement count

                logger.debug(f"Found database creation: {db_name} (Action: {action}, ObjAction: {obj_action})")
                self._record_object_reference(db_name, "DATABASE", obj_action, first_token)
                # Record the specific statement count - ADDED
                self.engine.record_statement(action, tree, self.current_file)
            else:
                 logger.warning(f"Create Database: Failed to extract name or token from {qual_name_node.pretty()}")
                 # Attempt to record statement count even if object recording fails
                 self.engine.record_statement(action, tree, self.current_file)

        # Added: record CLONE source databases
        for clone in tree.find_data('clone_clause'):
            qual_name_node = self._find_first_child_by_name(clone, 'qualified_name')
            if qual_name_node:
                source = self._extract_qualified_name(qual_name_node)
                tok = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
                if source and tok:
                    self._record_object_reference(source, "DATABASE", "CLONE", tok)
            # Ensure statement count happens even with CLONE (should occur above)

    def alter_warehouse_stmt(self, tree: Tree):
        """Visits `alter_warehouse_stmt` nodes. Extracts the `qualified_name` of the warehouse.

        Records the found warehouse as 'ALTER'.
        """
        self._debug_tree(tree, "Alter Warehouse Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            wh_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if wh_name and first_token:
                logger.debug(f"Found warehouse alteration: {wh_name}")
                self._record_object_reference(wh_name, "WAREHOUSE", "ALTER", first_token)
                # Record the ALTER_WAREHOUSE statement
                self.engine.record_statement("ALTER_WAREHOUSE", tree, self.current_file)

    def update_stmt(self, tree: Tree):
        """Visits `update_stmt` nodes. Extracts table references.

        Identifies the table being updated in UPDATE statements.
        Records found objects under 'UPDATE' action.
        Also ensures the destructive statement is recorded.
        """
        self._debug_tree(tree, "Update Statement")
        
        # Find the table name in the UPDATE clause
        table_ref = None
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'qualified_name':
                table_ref = child
                break
        
        if table_ref:
            table_name = self._extract_qualified_name(table_ref)
            first_token = next((t for t in table_ref.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found table being updated: {table_name}")
                # Record in the current context (e.g., task context)
                self._record_object_reference(table_name, "TABLE", "UPDATE", first_token)
                
                # Record the UPDATE statement
                self.engine.record_statement("UPDATE", tree, self.current_file)
                
                # Make sure to record the UPDATE destructive statement
                self.engine.record_destructive_statement("UPDATE", tree, self.current_file)
                # Recurse into nested SQL (expressions, where clauses) to capture dependencies
                for child in tree.children:
                    if isinstance(child, Tree):
                        self.visit(child)

    def drop_stmt(self, tree: Tree):
        """Visits `drop_stmt` nodes. Extracts the object being dropped.

        Identifies the database object being dropped (e.g., TABLE, VIEW, TASK).
        Records found objects under appropriate 'DROP' action.
        Also ensures the destructive statement is recorded.
        """
        self._debug_tree(tree, "Drop Statement")
        
        # Simplified approach: Check for specific patterns directly
        children = list(tree.children)
        obj_type = None
        obj_name = None
        first_token = None
        compound_obj_type = None  # For types like "EXTERNAL TABLE", "MATERIALIZED VIEW"
        
        # First look for object_type node containing the type token
        for child in children:
            if isinstance(child, Tree) and child.data == 'object_type':
                # Check children of object_type for specific tokens
                obj_type_tokens = []
                for type_token in child.children:
                    if isinstance(type_token, Token):
                        obj_type_tokens.append(type_token.type)
                
                # Check for single token types first
                if len(obj_type_tokens) == 1 and obj_type_tokens[0] in ('TABLE', 'VIEW', 'TASK', 'WAREHOUSE', 'DATABASE', 'SCHEMA', 'FUNCTION', 'SHARE', 'INTEGRATION', 'PIPE'):
                    obj_type = obj_type_tokens[0]
                    logger.debug(f"Found object type token: {obj_type}")
                    break
                
                # Check for compound types
                elif len(obj_type_tokens) > 1:
                    # Handle known compound types
                    if "EXTERNAL" in obj_type_tokens and "TABLE" in obj_type_tokens:
                        obj_type = "TABLE"  # Base type is still TABLE
                        compound_obj_type = "EXTERNAL_TABLE"
                    elif "MATERIALIZED" in obj_type_tokens and "VIEW" in obj_type_tokens:
                        obj_type = "VIEW"  # Base type is still VIEW
                        compound_obj_type = "MATERIALIZED_VIEW"
                    elif "EXTERNAL" in obj_type_tokens and "FUNCTION" in obj_type_tokens:
                        obj_type = "FUNCTION"  # Base type is still FUNCTION
                        compound_obj_type = "EXTERNAL_FUNCTION"
                    
                    if obj_type:
                        logger.debug(f"Found compound object type: {compound_obj_type} (base: {obj_type})")
                        break
                
        # If no object_type node, fallback to direct token search
        if not obj_type:
            # Check for direct object type tokens like TABLE, VIEW, etc. as direct children
            for i, child in enumerate(children):
                if isinstance(child, Token) and child.type in ('TABLE', 'VIEW', 'TASK', 'WAREHOUSE', 'DATABASE', 'SCHEMA', 'FUNCTION', 'SHARE', 'INTEGRATION', 'PIPE'):
                    obj_type = child.type
                    logger.debug(f"Found direct object type token: {obj_type}")
                    break

            # If still not found, look for DROP followed by object type tokens
            if not obj_type:
                found_drop = False
                obj_type_tokens = []
                
                for i, child in enumerate(children):
                    if isinstance(child, Token):
                        if child.type == 'DROP':
                            found_drop = True
                        # If we found DROP, collect potential object type tokens
                        elif found_drop:
                            obj_type_tokens.append(child.type)
                            
                            # Try to determine the type based on collected tokens
                            if child.type in ('TABLE', 'VIEW', 'TASK', 'WAREHOUSE', 'DATABASE', 'SCHEMA', 'FUNCTION', 'SHARE', 'INTEGRATION', 'PIPE'):
                                if len(obj_type_tokens) == 1:
                                    # Simple case: DROP followed by single type
                                    obj_type = child.type
                                    break
                                else:
                                    # Check for compound types
                                    # Flatten the compound type detection to avoid nested breaks
                                    compound_found = False
                                    
                                    if "EXTERNAL" in obj_type_tokens and "TABLE" in obj_type_tokens:
                                        obj_type = "TABLE"
                                        compound_obj_type = "EXTERNAL_TABLE"
                                        compound_found = True
                                    elif "MATERIALIZED" in obj_type_tokens and "VIEW" in obj_type_tokens:
                                        obj_type = "VIEW"
                                        compound_obj_type = "MATERIALIZED_VIEW"
                                        compound_found = True
                                    elif "EXTERNAL" in obj_type_tokens and "FUNCTION" in obj_type_tokens:
                                        obj_type = "FUNCTION"
                                        compound_obj_type = "EXTERNAL_FUNCTION"
                                        compound_found = True
                                    
                                    if compound_found:
                                        break

        logger.debug(f"Drop statement object type identified: {obj_type}, compound: {compound_obj_type}")
        
        # Find qualified_name node for object name
        qual_name_node = None
        for child in children:
            if isinstance(child, Tree) and child.data == 'qualified_name':
                qual_name_node = child
                break
        
        if qual_name_node:
            obj_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            logger.debug(f"Found object name: {obj_name}")
        
        # Record the object reference and statement
        if obj_type and obj_name and first_token:
            # Set last_drop_object_type for special handling in engine
            self.engine.last_drop_object_type = obj_type
            logger.debug(f"Setting engine.last_drop_object_type to {obj_type}")
            
            # Determine the appropriate action based on object type
            if compound_obj_type:
                action = f"DROP_{compound_obj_type}"
            elif obj_type == "SHARE":
                action = "DROP_SHARE"
            elif obj_type == "INTEGRATION":
                action = "DROP_INTEGRATION"
            elif obj_type == "PIPE":
                action = "DROP_PIPE"
            else:
                action = "DROP"
                
            # Record the object reference
            self._record_object_reference(obj_name, obj_type, action, first_token)
            
            # Record the specific DROP_X statement
            if compound_obj_type:
                specific_stmt_type = f"DROP_{compound_obj_type}"
            else:
                specific_stmt_type = f"DROP_{obj_type}"
            
            logger.debug(f"Recording statement count for {specific_stmt_type}")
            self.engine.record_statement(specific_stmt_type, tree, self.current_file)
            
            # Record it as a destructive statement
            logger.debug(f"Recording destructive statement for {specific_stmt_type}")
            self.engine.record_destructive_statement(specific_stmt_type, tree, self.current_file)
        else:
            logger.warning(f"Could not extract all required information from DROP statement. Type={obj_type}, Name={obj_name}, Token found={first_token is not None}")
            # Default to generic DROP statement
            self.engine.record_destructive_statement("DROP", tree, self.current_file)

    def use_stmt(self, tree: Tree):
        """Visits `use_stmt` nodes. Extracts the `object_type` and name.

        Handles both `USE <object_type> <qualified_name>` and `USE ROLE <identifier>`.
        Records the found object as 'USE'.
        """
        logger.debug("VISITOR: Beginning use_stmt method")
        self._debug_tree(tree, "Use Statement")
        obj_type = "UNKNOWN"
        obj_name = None
        first_token = None

        # Check for USE ROLE IDENTIFIER form first
        role_token = None
        identifier_token = None
        for i, child in enumerate(tree.children):
            if isinstance(child, Token) and child.type == 'ROLE':
                role_token = child
                if i + 1 < len(tree.children) and isinstance(tree.children[i+1], Token) and tree.children[i+1].type == 'IDENTIFIER':
                    identifier_token = tree.children[i+1]
                    break

        if role_token and identifier_token:
            obj_type = "ROLE"
            obj_name = identifier_token.value
            first_token = identifier_token
            logger.debug(f"VISITOR: Extracted ROLE usage: {obj_name}")
        else:
            # Handle USE <object_type> <qualified_name> form
            obj_type_node = self._find_first_child_by_name(tree, 'object_type')
            if obj_type_node and obj_type_node.children and isinstance(obj_type_node.children[0], Token):
                obj_type = obj_type_node.children[0].value.upper()
                logger.debug(f"VISITOR: Extracted object_type = {obj_type}")

            qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
            if qual_name_node:
                obj_name = self._extract_qualified_name(qual_name_node)
                first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
                if obj_name:
                    logger.debug(f"VISITOR: Extracted object name = {obj_name}")
                else:
                     logger.warning(f"VISITOR: Failed to extract object name from qualified_name: {qual_name_node}")
            else:
                logger.warning(f"VISITOR: Failed to find qualified_name node in non-ROLE use_stmt")

        # Record the object if we found name and type
        if obj_name and first_token and obj_type != "UNKNOWN":
            logger.debug(f"VISITOR: Recording USE action for {obj_type}: {obj_name}")
            self._record_object_reference(obj_name, obj_type, "USE", first_token)
            # Record the specific statement type
            self.engine.record_statement(f"USE_{obj_type}", tree, self.current_file)
        else:
            logger.warning(f"VISITOR: Could not record USE statement - Missing name, token, or type. Name: {obj_name}, Type: {obj_type}, Token found: {first_token is not None}")

    def create_function_stmt(self, tree: Tree):
        """Visits `create_function_stmt` nodes. Extracts the function name.

        Records the found function as 'CREATE'.
        """
        self._debug_tree(tree, "Create Function Statement")
        # The function name is usually the first qualified_name encountered directly
        # Need to be careful as arguments might also contain names
        # Let's find the qualified_name that isn't part of an argument_def
        func_name_node = None
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'qualified_name':
                # Crude check: Assume the first one not nested too deep is the name
                # A better approach might involve checking the parent chain if grammar is complex
                func_name_node = child 
                break 
            elif isinstance(child, Token) and child.type == 'IDENTIFIER': # Handle case where name isn't wrapped in qualified_name? Maybe not needed by grammar.
                 # Handle simple identifier name if grammar allows?
                 pass
        
        if func_name_node:
            func_name = self._extract_qualified_name(func_name_node)
            first_token = next((t for t in func_name_node.children if isinstance(t, Token)), None)
            if func_name and first_token:
                logger.debug(f"Found function creation: {func_name}")
                self._record_object_reference(func_name, "FUNCTION", "CREATE", first_token)
                # Record the statement count
                self.engine.record_statement("CREATE_FUNCTION", tree, self.current_file)
            else:
                logger.warning(f"Create Function: Failed to extract name or token from {func_name_node.pretty()}")
                # Attempt to record statement count even if object recording fails
                self.engine.record_statement("CREATE_FUNCTION", tree, self.current_file)
        else:
            logger.warning(f"Could not reliably determine function name in create_function_stmt: {tree.pretty()}")
            # Still record the statement count even if we couldn't extract the function name
            self.engine.record_statement("CREATE_FUNCTION", tree, self.current_file)

    def function_call(self, tree: Tree):
        """Visits `function_call` nodes. Extracts the function name.
        
        Records the found function as 'REFERENCE', excluding common built-ins.
        Uses the function name node for location info.
        """
        logger.debug(f"VISITOR: Entering function_call method for node: {tree.pretty()[:100]}...")
        self._debug_tree(tree, "Function Call")
        # Special handling for FLATTEN table function: record input and statement
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        func_name = self._extract_qualified_name(qual_name_node) if qual_name_node else None
        if func_name and func_name.upper() == 'FLATTEN':
            # Iterate named arguments to find INPUT => expression
            for named_args in tree.find_data('named_arg_list'):
                for named_arg in named_args.children:
                    if isinstance(named_arg, Tree) and named_arg.data == 'named_arg':
                        arg_name_token = next((t for t in named_arg.children if isinstance(t, Token) and t.type == 'IDENTIFIER'), None)
                        if arg_name_token and arg_name_token.value.upper() == 'INPUT':
                            expr_node = named_arg.children[-1]
                            for col_node in expr_node.find_data('qualified_name'):
                                col_name = self._extract_qualified_name(col_node)
                                col_token = next((t for t in col_node.children if isinstance(t, Token)), None)
                                if col_name and col_token:
                                    obj_type = 'COLUMN' if '.' in col_name else 'TABLE'
                                    logger.debug(f"Found FLATTEN input reference in function_call: {col_name}")
                                    # Record flatten action on input
                                    self._record_object_reference(col_name, obj_type, 'FLATTEN', col_token)
            # Record FLATTEN statement count
            self.engine.record_statement('FLATTEN', tree, self.current_file)
            return
        # Handle ML.PREDICT and ML.TRAIN calls
        if func_name and func_name.upper() in ('ML.PREDICT', 'ML.TRAIN'):
            action = 'ML_PREDICT' if func_name.upper() == 'ML.PREDICT' else 'ML_TRAIN'
            logger.debug(f"Found {action} function call: {func_name}")
            # Record model and table arguments
            for named_args in tree.find_data('named_arg_list'):
                for named_arg in named_args.children:
                    if isinstance(named_arg, Tree) and named_arg.data == 'named_arg':
                        arg_name_token = next((t for t in named_arg.children if isinstance(t, Token) and t.type == 'IDENTIFIER'), None)
                        expr_node = named_arg.children[-1]
                        if arg_name_token and expr_node:
                            arg_name = arg_name_token.value.upper()
                            for col_node in expr_node.find_data('qualified_name'):
                                name = self._extract_qualified_name(col_node)
                                token = next((t for t in col_node.children if isinstance(t, Token)), None)
                                if name and token:
                                    obj_type = 'MODEL' if arg_name == 'MODEL' else 'TABLE'
                                    self._record_object_reference(name, obj_type, action, token)
            # Record ML statement count once per function_call tree
            if not hasattr(self, '_ml_seen'):
                self._ml_seen = set()
            tree_id = id(tree)
            if tree_id not in self._ml_seen:
                self._ml_seen.add(tree_id)
                self.engine.record_statement(action, tree, self.current_file)
            return
        # Function name is typically the qualified_name child
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            func_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if func_name and first_token:
                # Avoid logging built-in functions like CURRENT_TIMESTAMP etc. unless desired
                # Basic check: skip common SQL functions (can be expanded)
                # Convert func_name to upper for case-insensitive comparison
                if func_name.upper() not in [
                    'CURRENT_TIMESTAMP', 'DATEADD', 'LEFT', 
                    'RIGHT', 'SUBSTR', 'UPPER', 'LOWER', 'TRIM', 
                    'SUM', 'COUNT', 'AVG', 'MIN', 'MAX', 'CAST', 'TRY_CAST'
                ]: # Add more as needed
                     logger.debug(f"Found function reference: {func_name}")
                     self._record_object_reference(func_name, "FUNCTION", "REFERENCE", first_token)
                else:
                    logger.debug(f"Skipping common/built-in function reference: {func_name}")
        else:
            logger.warning(f"Could not find qualified_name in function_call node: {tree.pretty()}")

    def delete_stmt(self, tree: Tree):
        """Visits `delete_stmt` nodes. Extracts table references.

        Identifies tables targeted by DELETE statements.
        Records found objects as 'DELETE'.
        Also ensures the destructive statement is recorded.
        """
        self._debug_tree(tree, "Delete Statement")
        
        # Find the table name in DELETE FROM clause
        table_ref = None
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'delete_from_clause':
                for subchild in child.children:
                    if isinstance(subchild, Tree) and subchild.data == 'qualified_name':
                        table_ref = subchild
                        break
        
        if table_ref:
            table_name = self._extract_qualified_name(table_ref)
            first_token = next((t for t in table_ref.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found table targeted by DELETE: {table_name}")
                self._record_object_reference(table_name, "TABLE", "DELETE", first_token)
                
                # Make sure to record the DELETE destructive statement
                self.engine.record_destructive_statement("DELETE", tree, self.current_file)
                # Recurse into nested SQL (expressions, where clauses) to capture dependencies
                for child in tree.children:
                    if isinstance(child, Tree):
                        self.visit(child)

    def truncate_stmt(self, tree: Tree):
        """Visits `truncate_stmt` nodes. Extracts table references.

        Identifies tables targeted by TRUNCATE statements.
        Records found objects as 'TRUNCATE'.
        Also ensures the destructive statement is recorded.
        """
        self._debug_tree(tree, "Truncate Statement")
        
        # Find the table name in TRUNCATE TABLE clause
        table_ref = self._find_first_child_by_name(tree, 'qualified_name')
        
        if table_ref:
            table_name = self._extract_qualified_name(table_ref)
            first_token = next((t for t in table_ref.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found table targeted by TRUNCATE: {table_name}")
                self._record_object_reference(table_name, "TABLE", "TRUNCATE", first_token)
                
                # Make sure to record the TRUNCATE_TABLE destructive statement
                self.engine.record_destructive_statement("TRUNCATE_TABLE", tree, self.current_file)

    def create_stage_stmt(self, tree: Tree):
        """Visits `create_stage_stmt` nodes. Extracts the stage name and options."""
        self._debug_tree(tree, "Create Stage Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            stage_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if stage_name and first_token:
                self._record_object_reference(stage_name, "STAGE", "CREATE", first_token)
                # Record the statement count
                self.engine.record_statement("CREATE_STAGE", tree, self.current_file)
            else:
                logger.warning(f"Create Stage: Failed to extract name or token from {qual_name_node.pretty()}")
                # Attempt to record statement count even if object recording fails
                self.engine.record_statement("CREATE_STAGE", tree, self.current_file)
        else:
            # If no qualified name was found at all, still record the statement
            logger.warning("Create Stage: No qualified_name node found in tree")
            self.engine.record_statement("CREATE_STAGE", tree, self.current_file)
            
        # Extract FILE_FORMAT and URL references if present
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'stage_param':
                # Iterate through tokens/nodes within stage_param
                param_children = child.children
                i = 0
                while i < len(param_children):
                    param = param_children[i]
                    if isinstance(param, Tree) and param.data == 'file_format_option':
                        # Handle inline file format options (e.g., TYPE = 'CSV')
                        option_name_token = None
                        for subparam in param.children:
                            if isinstance(subparam, Token) and subparam.type == 'IDENTIFIER':
                                option_name_token = subparam
                                break # Found the identifier token
                        if option_name_token:
                            self._record_object_reference(option_name_token.value, "OPTION", "REFERENCE", option_name_token)
                        i += 1 # Move past the file_format_option node
                    elif isinstance(param, Token) and param.type == 'FILE_FORMAT':
                        # Handle named file format reference (e.g., FILE_FORMAT = my_fmt)
                        # Expect EQ and qualified_name next
                        if i + 2 < len(param_children) and isinstance(param_children[i+1], Token) and param_children[i+1].type == 'EQ':
                            ff_node = param_children[i+2]
                            if isinstance(ff_node, Tree) and ff_node.data == 'qualified_name':
                                ff_name = self._extract_qualified_name(ff_node)
                                ff_token = next((t for t in ff_node.children if isinstance(t, Token)), None)
                                if ff_name and ff_token:
                                    self._record_object_reference(ff_name, "FILE_FORMAT", "REFERENCE", ff_token)
                                i += 3 # Move past FILE_FORMAT, EQ, qualified_name
                            else:
                                i += 1 # Move past FILE_FORMAT if structure unexpected
                        else:
                           i += 1 # Move past FILE_FORMAT if structure unexpected
                    elif isinstance(param, Token) and param.type == 'URL':
                        # Handle URL parameter
                        if i + 2 < len(param_children) and isinstance(param_children[i+1], Token) and param_children[i+1].type == 'EQ':
                             url_node = param_children[i+2]
                             # Assuming URL value is a token (e.g., SINGLE_QUOTED_STRING)
                             if isinstance(url_node, Token):
                                 self._record_object_reference(stage_name, "STAGE", "URL_REFERENCE", url_node)
                                 i += 3 # Move past URL, EQ, value
                             else:
                                i += 1 # Move past URL if structure unexpected
                        else:
                            i += 1 # Move past URL if structure unexpected
                    else:
                        # Unknown/unhandled parameter token/node
                        i += 1

    def create_file_format_stmt(self, tree: Tree):
        """Visits `create_file_format_stmt` nodes. Extracts the file format name and options."""
        self._debug_tree(tree, "Create File Format Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            format_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if format_name and first_token:
                self._record_object_reference(format_name, "FILE_FORMAT", "CREATE", first_token)
                # Record the statement count
                self.engine.record_statement("CREATE_FILE_FORMAT", tree, self.current_file)
            else:
                logger.warning(f"Create File Format: Failed to extract name or token from {qual_name_node.pretty()}")
                # Attempt to record statement count even if object recording fails
                self.engine.record_statement("CREATE_FILE_FORMAT", tree, self.current_file)
        else:
            # If no qualified name was found at all, still record the statement
            logger.warning("Create File Format: No qualified_name node found in tree")
            self.engine.record_statement("CREATE_FILE_FORMAT", tree, self.current_file)
            
        # Extract TYPE and file format options
        type_value = None
        for child in tree.children:
            if isinstance(child, Token) and child.type == 'TYPE':
                type_value = child.value
            elif isinstance(child, Tree) and child.data == 'file_format_option_kv':
                for param in child.children:
                    if isinstance(param, Token) and param.type == 'FIELD_DELIMITER':
                        self._record_object_reference(format_name, "FILE_FORMAT", "FIELD_DELIMITER", param)
        if type_value:
            self._record_object_reference(format_name, "FILE_FORMAT", f"TYPE_{type_value}", first_token)

    def copy_into_stmt(self, tree: Tree):
        """Visits `copy_into_stmt` nodes. Extracts source and target for COPY INTO, and options."""
        self._debug_tree(tree, "Copy Into Statement")

        copy_target_node = self._find_first_child_by_name(tree, 'copy_target')
        target_recorded = False
        target_name_str = None
        target_type = None
        target_node_for_loc = None

        if copy_target_node:
            qual_name_node = self._find_first_child_by_name(copy_target_node, 'qualified_name')
            stage_path_node = self._find_first_child_by_name(copy_target_node, 'STAGE_PATH')

            if qual_name_node:
                target_name_str = self._extract_qualified_name(qual_name_node)
                target_node_for_loc = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            elif stage_path_node:
                target_name_str = stage_path_node.children[0].value if stage_path_node.children else ""
                target_node_for_loc = stage_path_node
            
            if target_name_str and target_node_for_loc:
                # *** Determine target type based on name prefix ***
                if target_name_str.startswith('@'):
                    target_type = "STAGE"
                    self._record_object_reference(target_name_str, "STAGE", "COPY_INTO_STAGE", target_node_for_loc)
                    # Also record as a reference for source/target (if it's the target)
                    self._record_object_reference(target_name_str, "STAGE", "REFERENCE", target_node_for_loc)
                    # Record the specific statement count
                    self.engine.record_statement("COPY_INTO_STAGE", tree, self.current_file)
                else:
                    target_type = "TABLE"
                    self._record_object_reference(target_name_str, "TABLE", "COPY_INTO_TABLE", target_node_for_loc)
                    # Record the specific statement count
                    self.engine.record_statement("COPY_INTO_TABLE", tree, self.current_file)
                target_recorded = True
        
        if not target_recorded:
             logger.warning(f"Could not determine target (TABLE or STAGE) in COPY INTO statement: {tree.pretty()}")

        # --- Process Copy Source ---
        copy_source_node = self._find_first_child_by_name(tree, 'copy_source')
        if copy_source_node:
            source_qual_name_node = self._find_first_child_by_name(copy_source_node, 'qualified_name')
            source_stage_path_node = self._find_first_child_by_name(copy_source_node, 'STAGE_PATH')
            source_select_node = self._find_first_child_by_name(copy_source_node, 'select_stmt')

            source_name_str = None
            source_type = None
            source_node_for_loc = None
            action = "REFERENCE" # Default action for source

            if source_qual_name_node:
                source_name_str = self._extract_qualified_name(source_qual_name_node)
                source_node_for_loc = next((t for t in source_qual_name_node.children if isinstance(t, Token)), None)
                source_type = "TABLE" # Assume table if qualified name
            elif source_stage_path_node:
                source_name_str = source_stage_path_node.children[0].value if source_stage_path_node.children else ""
                source_node_for_loc = source_stage_path_node
                source_type = "STAGE"
                action = "COPY_FROM_STAGE" # More specific action for stages
            else:
                # Fallback: detect stage path token in children if grammar exposes it as Token
                for child in copy_source_node.children:
                    if isinstance(child, Token) and child.type == "STAGE_PATH":
                        source_name_str = child.value
                        source_node_for_loc = child
                        source_type = "STAGE"
                        action = "COPY_FROM_STAGE"
                        break
            
            if source_name_str and source_node_for_loc and source_type:
                 logger.debug(f"Found {source_type} source in COPY INTO: {source_name_str}")
                 self._record_object_reference(source_name_str, source_type, action, source_node_for_loc)
            elif source_select_node:
                # If source is a subquery, visit it to find references within
                logger.debug("Descending into SELECT statement within COPY INTO source...")
                self.visit(source_select_node)
            else:
                logger.warning(f"Could not determine source (TABLE/STAGE/Subquery) in COPY INTO statement: {copy_source_node.pretty()}")

        # --- Process Copy Options (e.g., FILE_FORMAT reference) ---
        # Record referenced file formats in COPY INTO statement
        for token in tree.scan_values(lambda v: isinstance(v, Token) and v.type == "SINGLE_QUOTED_STRING"):
            # Strip surrounding quotes for consistency
            ff_name = token.value.strip("'").strip('"')
            self._record_object_reference(ff_name, "FILE_FORMAT", "REFERENCE", token)
        # Fallback: record any stage path tokens in COPY INTO source by value starting with '@'
        for token in tree.scan_values(lambda v: isinstance(v, Token) and isinstance(v.value, str) and v.value.startswith('@')):
            self._record_object_reference(token.value, "STAGE", "COPY_FROM_STAGE", token)

    def create_stream_stmt(self, tree: Tree):
        """Visits `create_stream_stmt` nodes. Extracts the stream name, base object, and parameters."""
        self._debug_tree(tree, "Create Stream Statement")
        # Extract stream name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        stream_name = None
        if qual_name_node:
            stream_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if stream_name and first_token:
                self._record_object_reference(stream_name, "STREAM", "CREATE_STREAM", first_token)
                self.engine.record_statement("CREATE_STREAM", tree, self.current_file)
        # Extract base table or stage reference (second qualified_name)
        qual_nodes = [c for c in tree.children if isinstance(c, Tree) and c.data == 'qualified_name']
        if len(qual_nodes) >= 2:
            base_node = qual_nodes[1]
            base_name = self._extract_qualified_name(base_node)
            base_token = next((t for t in base_node.children if isinstance(t, Token)), None)
            # Determine base type from preceding token
            base_type = None
            idx = tree.children.index(base_node)
            if idx >= 1 and isinstance(tree.children[idx-1], Token):
                if tree.children[idx-1].type in ('TABLE', 'STAGE'):
                    base_type = tree.children[idx-1].type
            if base_name and base_token and base_type:
                self._record_object_reference(base_name, base_type, "REFERENCE", base_token)
        # Extract at_before_clause parameters
        at_clause = self._find_first_child_by_name(tree, 'at_before_clause')
        if at_clause:
            for param in at_clause.find_data('at_before_param'):
                first_token = param.children[0] if param.children else None
                if isinstance(first_token, Token) and stream_name:
                    param_name = first_token.value.upper()
                    self._record_object_reference(stream_name, "STREAM", param_name, first_token)

    def alter_stream_stmt(self, tree: Tree):
        """Visits `alter_stream_stmt` nodes. Extracts the stream name and updated parameters."""
        self._debug_tree(tree, "Alter Stream Statement")
        # Extract stream name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        stream_name = None
        if qual_name_node:
            stream_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if stream_name and first_token:
                self._record_object_reference(stream_name, "STREAM", "ALTER_STREAM", first_token)
                self.engine.record_statement("ALTER_STREAM", tree, self.current_file)
        # Extract stream parameters (could be nested within stream_set_clause)
        for param in tree.find_data('stream_param'):
            param_token = param.children[0] if param.children else None
            if isinstance(param_token, Token) and stream_name:
                param_name = param_token.value.upper()
                self._record_object_reference(stream_name, "STREAM", param_name, param_token)

    def create_pipe_stmt(self, tree: Tree):
        """Visits `create_pipe_stmt` nodes. Extracts the pipe name, parameters, and embedded COPY INTO statement."""
        self._debug_tree(tree, "Create Pipe Statement")
        # Extract pipe name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        pipe_name = None
        if qual_name_node:
            pipe_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if pipe_name and first_token:
                self._record_object_reference(pipe_name, "PIPE", "CREATE_PIPE", first_token)
                self.engine.record_statement("CREATE_PIPE", tree, self.current_file)
        # Extract pipe parameters
        for param in tree.find_data('pipe_param'):
            param_token = param.children[0] if param.children else None
            if isinstance(param_token, Token) and pipe_name:
                param_name = param_token.type
                self._record_object_reference(pipe_name, "PIPE", param_name, param_token)
        # Visit embedded COPY INTO statement within the pipe
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'copy_into_stmt':
                old_context = getattr(self, 'current_context', None)
                self.current_context = {'type': 'PIPE', 'name': pipe_name}
                try:
                    self.visit(child)
                finally:
                    self.current_context = old_context

    def alter_pipe_stmt(self, tree: Tree):
        """Visits `alter_pipe_stmt` nodes. Extracts the pipe name and updated parameters."""
        self._debug_tree(tree, "Alter Pipe Statement")
        # Extract pipe name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        pipe_name = None
        first_token = None
        if qual_name_node:
            pipe_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
        # Determine if this is a SET alter or a REFRESH alter
        has_set = any(isinstance(child, Token) and child.type == 'SET' for child in tree.children)
        # Only count SET variant as ALTER_PIPE statement
        if pipe_name and first_token and has_set:
            self._record_object_reference(pipe_name, "PIPE", "ALTER_PIPE", first_token)
            self.engine.record_statement("ALTER_PIPE", tree, self.current_file)
        # Record REFRESH as an object action, do not count as ALTER_PIPE
        for child in tree.children:
            if isinstance(child, Token) and child.type == 'REFRESH' and pipe_name:
                self._record_object_reference(pipe_name, "PIPE", "REFRESH", child)
        # Extract updated pipe parameters (common to SET variant)
        for param in tree.find_data('pipe_param'):
            param_token = param.children[0] if param.children else None
            if isinstance(param_token, Token) and pipe_name:
                param_name = param_token.type
                self._record_object_reference(pipe_name, "PIPE", param_name, param_token)

    def enable_search_optimization_stmt(self, tree: Tree):
        """Visits `enable_search_optimization_stmt` nodes."""
        logger.debug(f"VISITOR: Entering enable_search_optimization_stmt: {tree.pretty()[:100]}")
        self._debug_tree(tree, "Enable Search Optimization Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            table_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found ENABLE SEARCH OPTIMIZATION on table: {table_name}")
                self._record_object_reference(table_name, "TABLE", "ENABLE_SEARCH_OPTIMIZATION", first_token)
                self.engine.record_statement("ENABLE_SEARCH_OPTIMIZATION", tree, self.current_file)

    def disable_search_optimization_stmt(self, tree: Tree):
        """Visits `disable_search_optimization_stmt` nodes."""
        logger.debug(f"VISITOR: Entering disable_search_optimization_stmt: {tree.pretty()[:100]}")
        self._debug_tree(tree, "Disable Search Optimization Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            table_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found DISABLE SEARCH OPTIMIZATION on table: {table_name}")
                self._record_object_reference(table_name, "TABLE", "DISABLE_SEARCH_OPTIMIZATION", first_token)
                self.engine.record_statement("DISABLE_SEARCH_OPTIMIZATION", tree, self.current_file)

    def alter_search_optimization_stmt(self, tree: Tree):
        """Visits `alter_search_optimization_stmt` nodes."""
        logger.debug(f"VISITOR: Entering alter_search_optimization_stmt: {tree.pretty()[:100]}")
        self._debug_tree(tree, "Alter Search Optimization Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            table_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found ALTER SEARCH OPTIMIZATION on table: {table_name}")
                self._record_object_reference(table_name, "TABLE", "ALTER_SEARCH_OPTIMIZATION", first_token)
                self.engine.record_statement("ALTER_SEARCH_OPTIMIZATION", tree, self.current_file)

    def grant_role_stmt(self, tree: Tree):
        """Visits `grant_role_stmt` nodes. Records role grants between roles."""
        self._debug_tree(tree, "Grant Role Statement")
        qnames = list(tree.find_data('qualified_name'))
        if len(qnames) == 2:
            granted_node, target_node = qnames[0], qnames[1]
            granted_name = self._extract_qualified_name(granted_node)
            target_name = self._extract_qualified_name(target_node)
            granted_token = next((t for t in granted_node.children if isinstance(t, Token)), None)
            target_token = next((t for t in target_node.children if isinstance(t, Token)), None)
            if granted_name and target_name and granted_token and target_token:
                logger.debug(f"Found GRANT ROLE: {granted_name} TO ROLE: {target_name}")
                self._record_object_reference(granted_name, "ROLE", "GRANT_ROLE", granted_token)
                self._record_object_reference(target_name, "ROLE", "GRANT_ROLE", target_token)
                self.engine.record_statement("GRANT_ROLE", tree, self.current_file)
                self.engine.result.add_dependency("ROLE", target_name, "ROLE", granted_name, "GRANT_ROLE")

    def revoke_role_stmt(self, tree: Tree):
        """Visits `revoke_role_stmt` nodes. Records role revocations between roles."""
        self._debug_tree(tree, "Revoke Role Statement")
        qnames = list(tree.find_data('qualified_name'))
        if len(qnames) == 2:
            revoked_node, target_node = qnames[0], qnames[1]
            revoked_name = self._extract_qualified_name(revoked_node)
            target_name = self._extract_qualified_name(target_node)
            revoked_token = next((t for t in revoked_node.children if isinstance(t, Token)), None)
            target_token = next((t for t in target_node.children if isinstance(t, Token)), None)
            if revoked_name and target_name and revoked_token and target_token:
                logger.debug(f"Found REVOKE ROLE: {revoked_name} FROM ROLE: {target_name}")
                self._record_object_reference(revoked_name, "ROLE", "REVOKE_ROLE", revoked_token)
                self._record_object_reference(target_name, "ROLE", "REVOKE_ROLE", target_token)
                self.engine.record_statement("REVOKE_ROLE", tree, self.current_file)
                self.engine.result.add_dependency("ROLE", target_name, "ROLE", revoked_name, "REVOKE_ROLE")

    def create_role_stmt(self, tree: Tree):
        """Visits `create_role_stmt` nodes. Records role creation statements."""
        self._debug_tree(tree, "Create Role Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            role_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if role_name and first_token:
                logger.debug(f"Found CREATE ROLE: {role_name}")
                # Record creation of the role
                self._record_object_reference(role_name, "ROLE", "CREATE_ROLE", first_token)
                self.engine.record_statement("CREATE_ROLE", tree, self.current_file)

    def create_job_stmt(self, tree: Tree):
        """Visits `create_job_stmt` nodes. Records job creation statements."""
        logger.debug(f"VISITOR: Entering create_job_stmt: {tree.pretty()[:100]}")
        self._debug_tree(tree, "Create Job Statement")
        # Extract job name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            job_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if job_name and first_token:
                logger.debug(f"Found CREATE JOB: {job_name}")
                self._record_object_reference(job_name, "JOB", "CREATE_JOB", first_token)
                self.engine.record_statement("CREATE_JOB", tree, self.current_file)
        # Process job parameters (warehouse, schedule, max_concurrency)
        for child in tree.children:
            if isinstance(child, Tree) and child.data == 'job_param':
                param_token = child.children[0] if child.children else None
                if isinstance(param_token, Token):
                    if param_token.type == 'WAREHOUSE':
                        # Next node is qualified_name at index 2
                        if len(child.children) >= 3 and isinstance(child.children[2], Tree):
                            wh_node = child.children[2]
                            wh_name = self._extract_qualified_name(wh_node)
                            wh_token = next((t for t in wh_node.children if isinstance(t, Token)), None)
                            if wh_name and wh_token:
                                self._record_object_reference(wh_name, "WAREHOUSE", "REFERENCE", wh_token)
                    elif param_token.type == 'SCHEDULE':
                        # Schedule value is the STRING token at index 2
                        if len(child.children) >= 3 and isinstance(child.children[2], Token):
                            sched_token = child.children[2]
                            self._record_object_reference(job_name, "JOB", "SCHEDULE", sched_token)
                    elif param_token.type == 'MAX_CONCURRENCY':
                        if len(child.children) >= 3 and isinstance(child.children[2], Token):
                            mc_token = child.children[2]
                            self._record_object_reference(job_name, "JOB", "MAX_CONCURRENCY", mc_token)

    def alter_job_stmt(self, tree: Tree):
        """Visits `alter_job_stmt` nodes. Records job alteration statements."""
        logger.debug(f"VISITOR: Entering alter_job_stmt: {tree.pretty()[:100]}")
        self._debug_tree(tree, "Alter Job Statement")
        # Extract job name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        job_name = None
        if qual_name_node:
            job_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if job_name and first_token:
                self._record_object_reference(job_name, "JOB", "ALTER_JOB", first_token)
                self.engine.record_statement("ALTER_JOB", tree, self.current_file)
        # Identify specific actions
        for i, child in enumerate(tree.children):
            if isinstance(child, Token):
                if child.type == 'SUSPEND':
                    self._record_object_reference(job_name, "JOB", "SUSPEND", child)
                elif child.type == 'RESUME':
                    self._record_object_reference(job_name, "JOB", "RESUME", child)
                elif child.type == 'REMOVE':
                    # REMOVE SCHEDULE
                    self._record_object_reference(job_name, "JOB", "REMOVE_SCHEDULE", child)
                elif child.type == 'ADD':
                    # ADD SCHEDULE with STRING token
                    sched_str = None
                    for j in range(i+1, len(tree.children)):
                        if isinstance(tree.children[j], Token) and tree.children[j].type == 'SINGLE_QUOTED_STRING':
                            sched_str = tree.children[j]
                            break
                    if sched_str:
                        self._record_object_reference(job_name, "JOB", "ADD_SCHEDULE", sched_str)

    # Generic handler for simple qualified_name-based statement visitors
    def _handle_simple_qn_stmt(self, tree: Tree, obj_type: str, action: str, prefix: str):
        """Generic handler for simple qualified_name-based statements.

        Prioritizes finding a qualified_name node. If found, uses its last
        identifier token. If not found, falls back to the last direct
        IDENTIFIER token child of the statement node.
        """
        self._debug_tree(tree, prefix)
        name = None
        token = None

        # 1. Try finding a qualified_name node first
        qual_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_node:
            name = self._extract_qualified_name(qual_node)
            # Try to get the *last* identifier token from the qualified name
            token = next(reversed([t for t in qual_node.children if isinstance(t, Token) and t.type == 'IDENTIFIER']), None)
            if name and token:
                logger.debug(f"{prefix}: Found qualified_name '{name}', using last token '{token.value}'.")
            elif name:
                # If name extracted but no suitable token, try first token as fallback
                token = next((t for t in qual_node.children if isinstance(t, Token)), None)
                if token:
                    logger.warning(f"{prefix}: Found qualified_name '{name}', but no IDENTIFIER token inside. Using first token '{token.value}' as fallback.")
                else:
                    logger.warning(f"{prefix}: Found qualified_name '{name}' but could not extract any token.")
                    name = None # Invalidate if no token found
            else:
                logger.warning(f"{prefix}: Found qualified_name node but failed to extract name.")
                name = None # Ensure name is None if extraction failed

        # 2. If no qualified_name found or extraction failed, find the last direct IDENTIFIER token
        if not name or not token:
            logger.debug(f"{prefix}: No valid qualified_name found or extracted. Searching for last direct IDENTIFIER.")
            direct_children = list(tree.children)
            meaningful_identifiers = []
            keywords_to_skip = {'IF', 'EXISTS', 'NOT'} # Add more SQL keywords if necessary

            # Find all direct IDENTIFIER children, filtering keywords
            for child in direct_children:
                if isinstance(child, Token) and child.type == 'IDENTIFIER':
                    if child.value.upper() not in keywords_to_skip:
                        meaningful_identifiers.append(child)
            
            logger.debug(f"{prefix}: Found direct meaningful IDENTIFIERs: {[t.value for t in meaningful_identifiers]}")

            if meaningful_identifiers:
                last_identifier_token = meaningful_identifiers[-1]
                # Check if we already found a name from qual_node but just lacked a token
                if name and not token:
                     token = last_identifier_token
                     logger.debug(f"{prefix}: Using last IDENTIFIER '{token.value}' as token for previously found name '{name}'.")
                # Otherwise, use this identifier as both name and token
                elif not name:
                     name = last_identifier_token.value
                     token = last_identifier_token
                     logger.debug(f"{prefix}: Fallback - Using last direct IDENTIFIER '{name}'.")
            else:
                 logger.warning(f"{prefix}: Fallback - Could not find any suitable direct IDENTIFIER token either.")


        # 3. Recording
        if name and token:
            # Ensure the token is valid
            if not isinstance(token, Token):
                logger.error(f"{prefix}: Invalid token type ({type(token)}) for recording. Aborting object record.")
                name = None # Prevent recording

            if name: # Check name again
                 logger.debug(f"{prefix}: Recording object reference: Name='{name}', Type='{obj_type}', Action='{action}' using token '{token.value}' ({token.type})")
                 self._record_object_reference(name, obj_type, action, token)
                 # Record the statement count using the specific action
                 # This assumes the calling method (dynamic or explicit) passes the correct final action name
                 logger.debug(f"{prefix}: Recording statement count: '{action}'") # Added specific log
                 self.engine.record_statement(action, tree, self.current_file)
            # else: The error log for invalid token handles this case

        else:
            logger.error(f"{prefix}: Failed to find valid object name or location token. Name='{name}', Token found: {token is not None}. Node: {tree.pretty()}")
            # Still record the statement count even if object identification fails, using the provided action.
            # Check if action is valid before recording?
            logger.debug(f"{prefix}: Recording statement count '{action}' despite object failure.") # Added specific log
            self.engine.record_statement(action, tree, self.current_file)

    # Dynamically register simple qualified_name statement visitors
    SIMPLE_QN_METHODS = [
        ('create_row_access_policy_stmt', 'ROW_ACCESS_POLICY', 'CREATE_ROW_ACCESS_POLICY', 'Create Row Access Policy'),
        ('alter_row_access_policy_stmt', 'ROW_ACCESS_POLICY', 'ALTER_ROW_ACCESS_POLICY', 'Alter Row Access Policy'),
        ('drop_row_access_policy_stmt', 'ROW_ACCESS_POLICY', 'DROP_ROW_ACCESS_POLICY', 'Drop Row Access Policy'),
        ('create_masking_policy_stmt', 'MASKING_POLICY', 'CREATE_MASKING_POLICY', 'Create Masking Policy'),
        ('create_alert_stmt', 'ALERT', 'CREATE_ALERT', 'Create Alert'),
        ('alter_alert_stmt', 'ALERT', 'ALTER_ALERT', 'Alter Alert'),
        ('drop_alert_stmt', 'ALERT', 'DROP_ALERT', 'Drop Alert'),
        ('create_iceberg_table_stmt', 'ICEBERG_TABLE', 'CREATE_ICEBERG_TABLE', 'Create Iceberg Table'),
        ('alter_iceberg_table_stmt', 'ICEBERG_TABLE', 'ALTER_ICEBERG_TABLE', 'Alter Iceberg Table'),
        ('drop_iceberg_table_stmt', 'ICEBERG_TABLE', 'DROP_ICEBERG_TABLE', 'Drop Iceberg Table'),
        ('create_package_stmt', 'PACKAGE', 'CREATE_PACKAGE', 'Create Package'),
        ('install_package_stmt', 'PACKAGE', 'INSTALL_PACKAGE', 'Install Package'),
        ('remove_package_stmt', 'PACKAGE', 'REMOVE_PACKAGE', 'Remove Package'),
        ('create_authentication_policy_stmt', 'AUTHENTICATION_POLICY', 'CREATE_AUTHENTICATION_POLICY', 'Create Authentication Policy'),
        ('alter_authentication_policy_stmt', 'AUTHENTICATION_POLICY', 'ALTER_AUTHENTICATION_POLICY', 'Alter Authentication Policy'),
        ('drop_authentication_policy_stmt', 'AUTHENTICATION_POLICY', 'DROP_AUTHENTICATION_POLICY', 'Drop Authentication Policy'),
        ('create_resource_monitor_stmt', 'RESOURCE_MONITOR', 'CREATE_RESOURCE_MONITOR', 'Create Resource Monitor'),
        ('create_share_stmt', 'SHARE', 'CREATE_SHARE', 'Create Share'),
        ('alter_share_stmt', 'SHARE', 'ALTER_SHARE', 'Alter Share'),
        ('drop_share_stmt', 'SHARE', 'DROP_SHARE', 'Drop Share'),
        ('create_integration_stmt', 'INTEGRATION', 'CREATE_INTEGRATION', 'Create Integration'),
        ('alter_integration_stmt', 'INTEGRATION', 'ALTER_INTEGRATION', 'Alter Integration'),
        ('drop_integration_stmt', 'INTEGRATION', 'DROP_INTEGRATION', 'Drop Integration'),
        ('create_external_table_stmt', 'EXTERNAL TABLE', 'CREATE_EXTERNAL_TABLE', 'Create External Table'),
        ('alter_external_table_stmt', 'EXTERNAL TABLE', 'ALTER_EXTERNAL_TABLE', 'Alter External Table'),
        ('drop_external_table_stmt', 'EXTERNAL TABLE', 'DROP_EXTERNAL_TABLE', 'Drop External Table'),
        ('create_materialized_view_stmt', 'MATERIALIZED VIEW', 'CREATE_MATERIALIZED_VIEW', 'Create Materialized View'),
        ('alter_materialized_view_stmt', 'MATERIALIZED VIEW', 'ALTER_MATERIALIZED_VIEW', 'Alter Materialized View'),
        ('drop_materialized_view_stmt', 'MATERIALIZED VIEW', 'DROP_MATERIALIZED_VIEW', 'Drop Materialized View'),
        ('create_external_function_stmt', 'EXTERNAL FUNCTION', 'CREATE_EXTERNAL_FUNCTION', 'Create External Function'),
        ('alter_external_function_stmt', 'EXTERNAL FUNCTION', 'ALTER_EXTERNAL_FUNCTION', 'Alter External Function'),
        ('drop_external_function_stmt', 'EXTERNAL FUNCTION', 'DROP_EXTERNAL_FUNCTION', 'Drop External Function'),
        ('create_network_policy_stmt', 'NETWORK POLICY', 'CREATE_NETWORK_POLICY', 'Create Network Policy'),
        ('alter_network_policy_stmt', 'NETWORK POLICY', 'ALTER_NETWORK_POLICY', 'Alter Network Policy'),
        ('drop_network_policy_stmt', 'NETWORK POLICY', 'DROP_NETWORK_POLICY', 'Drop Network Policy'),
        ('CREATE_REPLICATION_STMT', 'REPLICATION', 'CREATE_REPLICATION', 'Create Replication'),
        ('ALTER_REPLICATION_STMT', 'REPLICATION', 'ALTER_REPLICATION', 'Alter Replication'),
        ('CREATE_ACCOUNT_STMT', 'ACCOUNT', 'CREATE_ACCOUNT', 'Create Account'),
        ('ALTER_ACCOUNT_STMT', 'ACCOUNT', 'ALTER_ACCOUNT', 'Alter Account'),
        ('DROP_ACCOUNT_STMT', 'ACCOUNT', 'DROP_ACCOUNT', 'Drop Account'),
        ('SHOW_ACCOUNTS_STMT', 'ACCOUNT', 'SHOW_ACCOUNTS', 'Show Accounts'),
        ('ALTER_SESSION_STMT', 'SESSION', 'ALTER_SESSION', 'Alter Session'),
        ('SHOW_PARAMETERS_STMT', 'SESSION', 'SHOW_PARAMETERS', 'Show Parameters'),
        ('LIST_STMT', 'STAGE', 'LIST_STAGE', 'List Stage'),
        ('GET_STMT', 'STAGE', 'GET_STAGE', 'Get Stage'),
        ('REMOVE_STMT', 'STAGE', 'REMOVE_STAGE', 'Remove Stage'),
        ('ALTER_STAGE_STMT', 'STAGE', 'ALTER_STAGE', 'Alter Stage'),
    ]
    for _name, _obj_type, _action, _label in SIMPLE_QN_METHODS:
        # Use locals() to define methods in class namespace without referencing SQLVisitor
        locals()[_name.lower()] = (
            lambda obj_type, action, label: 
                (lambda self, tree: self._handle_simple_qn_stmt(tree, obj_type, action, f"{label} Statement"))
        )(_obj_type, _action, _label)

    def create_task_stmt(self, tree: Tree):
        """Visits `create_task_stmt` nodes. Extracts task name, warehouse, dependencies, and visits AS clause."""
        self._debug_tree(tree, "Create Task Statement")
        task_name = None
        task_name_node = self._find_first_child_by_name(tree, 'qualified_name')

        # 1. Extract Task Name & Record Creation
        if task_name_node:
            task_name = self._extract_qualified_name(task_name_node)
            first_token = next((t for t in task_name_node.children if isinstance(t, Token)), None)
            if task_name and first_token:
                self._record_object_reference(task_name, "TASK", "CREATE_TASK", first_token)
                self.engine.record_statement("CREATE_TASK", tree, self.current_file)
            else:
                logger.warning(f"CREATE TASK: Could not extract task name or token from {task_name_node.pretty()}. Aborting analysis for this statement.")
                return # Cannot proceed without task name
        else:
             logger.error(f"CREATE TASK: Could not find qualified_name for task name in {tree.pretty()}. Aborting analysis.")
             return # Cannot proceed without task name

        # 2. Process Parameters (Warehouse, AFTER Dependencies)
        # Directly find all 'task_param' subtrees
        for param_node in tree.find_data('task_param'):
             first_child_token = next((c for c in param_node.children if isinstance(c, Token)), None)
             if not first_child_token:
                 logger.warning(f"CREATE TASK: Found task_param node with no token children: {param_node.pretty()}")
                 continue

             # --- Handle WAREHOUSE ---
             if first_child_token.type == 'WAREHOUSE':
                 wh_node = self._find_first_child_by_name(param_node, 'qualified_name')
                 if wh_node:
                     wh_name = self._extract_qualified_name(wh_node)
                     wh_token = next((t for t in wh_node.children if isinstance(t, Token)), None)
                     if wh_name and wh_token:
                         self._record_object_reference(wh_name, "WAREHOUSE", "REFERENCE", wh_token)
                     else:
                         logger.warning(f"CREATE TASK: WAREHOUSE param found, but failed to extract name/token from its qualified_name node {wh_node.pretty()}")
                 else:
                     logger.warning(f"CREATE TASK: WAREHOUSE param found, but no qualified_name node within: {param_node.pretty()}")

             # --- Handle AFTER ---
             elif first_child_token.type == 'AFTER':
                 # Find ALL qualified_name nodes within this specific AFTER parameter node
                 dependency_nodes = list(param_node.find_data('qualified_name'))
                 if not dependency_nodes:
                     logger.warning(f"CREATE TASK: AFTER param found, but no qualified_name nodes within: {param_node.pretty()}")
                 else:
                     logger.debug(f"CREATE TASK: Found {len(dependency_nodes)} dependencies in AFTER clause for task '{task_name}'.")
                     for qn_node in dependency_nodes:
                         # find_data can return the node itself if it matches, double-check type
                         if isinstance(qn_node, Tree) and qn_node.data == 'qualified_name':
                             dep_task_name = self._extract_qualified_name(qn_node)
                             if dep_task_name:
                                 logger.debug(f"CREATE TASK: Recording AFTER dependency: {task_name} -> {dep_task_name}")
                                 # task_name is guaranteed to exist here due to checks at the start
                                 self.engine.result.add_dependency("TASK", task_name, "TASK", dep_task_name, "ADDED_AFTER")
                             else:
                                 logger.warning(f"CREATE TASK: Failed to extract dependency task name from node {qn_node.pretty()}")
                         else:
                              logger.warning(f"CREATE TASK: Unexpected node type found by find_data in AFTER param: {type(qn_node)}")

             # --- Handle other params like SCHEDULE if needed ---
             # elif first_child_token.type == 'SCHEDULE':
             #     pass # Add logic to extract schedule string

        # 3. Visit AS Clause Body
        old_context = getattr(self, 'current_context', None)
        self.current_context = {'type': 'TASK', 'name': task_name} # Set context before visiting AS body
        try:
            as_clause_body = None
            as_found = False
            node_after_as = None
            children_iter = iter(tree.children) # Use iterator to find node after AS

            # Find AS token and the node immediately after it
            for child in children_iter:
                if isinstance(child, Token) and child.type == 'AS':
                    as_found = True
                    node_after_as = next(children_iter, None) # Get the next item
                    break # Stop after finding AS and the next node

            if as_found and isinstance(node_after_as, Tree):
                # Check if the node itself is the body or a wrapper
                if node_after_as.data in ('select_stmt', 'insert_stmt', 'update_stmt', 'delete_stmt', 'merge_stmt', 'call_procedure_stmt'):
                     as_clause_body = node_after_as
                elif node_after_as.data == '_statement_wrapper': # Check common wrapper name
                     # Look for the actual statement inside the wrapper
                     potential_body = next((c for c in node_after_as.children if isinstance(c, Tree) and c.data in ('select_stmt', 'insert_stmt', 'update_stmt', 'delete_stmt', 'merge_stmt', 'call_procedure_stmt')), None)
                     if potential_body:
                          as_clause_body = potential_body
                     else:
                          logger.warning(f"CREATE TASK: Found _statement_wrapper after AS, but no known statement inside: {node_after_as.pretty()}")
                elif node_after_as.data == 'statement': # Handle generic statement wrapper
                     logger.debug(f"CREATE TASK: Node after AS is 'statement'. Looking inside for actual statement...")
                     potential_body = next((c for c in node_after_as.children if isinstance(c, Tree) and c.data in ('select_stmt', 'insert_stmt', 'update_stmt', 'delete_stmt', 'merge_stmt', 'call_procedure_stmt')), None)
                     if potential_body:
                          as_clause_body = potential_body
                     else:
                          logger.warning(f"CREATE TASK: Found 'statement' node after AS, but no known statement type inside: {node_after_as.pretty()}")
                else: # All checks failed
                     logger.warning(f"CREATE TASK: Node after AS is unexpected type '{node_after_as.data}'. Cannot determine AS clause body.")

                # Visit the body if found
                if as_clause_body:
                    logger.debug(f"CREATE TASK: Visiting AS clause ({as_clause_body.data}) for task {task_name}")
                    self.visit(as_clause_body)
                # else: Warning already logged above if body wasn't identified

            elif as_found: # AS was found, but the node after wasn't a Tree or didn't exist
                logger.warning(f"CREATE TASK: AS keyword found, but node after AS is not a valid statement tree (found: {type(node_after_as)}).")
            else: # AS not found at all
                 logger.warning(f"CREATE TASK: No AS keyword found in statement: {tree.pretty()}")

        finally:
            self.current_context = old_context # Restore context

    def alter_task_stmt(self, tree: Tree):
        """Visits `alter_task_stmt` nodes. Records task alteration statements and dependencies."""
        self._debug_tree(tree, "Alter Task Statement")
        task_name = None
        first_token = None

        # Extract task name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            task_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if task_name and first_token:
                self._record_object_reference(task_name, "TASK", "ALTER_TASK", first_token)
                self.engine.record_statement("ALTER_TASK", tree, self.current_file)

        # Process different ALTER TASK actions
        action_type = None # e.g., "ADD_AFTER", "REMOVE_AFTER", "SET", "SUSPEND", "RESUME"
        action_node = None # Store the relevant node (e.g., the set_clause Tree) or token
        after_token_index = -1 # Store index relative to main tree if AFTER is found directly

        logger.debug(f"ALTER TASK: Analyzing children to determine action: {tree.children}")

        for i, child in enumerate(tree.children):
            # A. Check for direct action Tokens
            if isinstance(child, Token):
                token_type = child.type
                logger.debug(f"ALTER TASK: Checking direct Token '{token_type}' at index {i}")
                if token_type == 'SUSPEND':
                    action_type = "SUSPEND"
                    action_node = child # Store the token itself
                    break
                elif token_type == 'RESUME':
                    action_type = "RESUME"
                    action_node = child # Store the token itself
                    break
                elif token_type == 'SET':
                    # Assume SET action, details processed later
                    action_type = "SET"
                    action_node = child # Store the SET token (or find a set_clause node later)
                    break # Found primary action type
                elif token_type == 'ADD':
                    # Check if next is AFTER
                    if i + 1 < len(tree.children) and isinstance(tree.children[i+1], Token) and tree.children[i+1].type == 'AFTER':
                        action_type = "ADD_AFTER"
                        action_node = tree.children[i+1] # Store the AFTER token
                        after_token_index = i + 1
                        break
                    else:
                        logger.warning("ALTER TASK: Found ADD token without subsequent AFTER token.")
                        # Continue searching in case ADD AFTER is nested in a Tree
                elif token_type == 'REMOVE':
                     # Check if next is AFTER
                    if i + 1 < len(tree.children) and isinstance(tree.children[i+1], Token) and tree.children[i+1].type == 'AFTER':
                        action_type = "REMOVE_AFTER"
                        action_node = tree.children[i+1] # Store the AFTER token
                        after_token_index = i + 1
                        break
                    else:
                        logger.warning("ALTER TASK: Found REMOVE token without subsequent AFTER token.")
                        # Continue searching

            # B. Check for action clause Trees
            elif isinstance(child, Tree):
                node_data = child.data.lower() # Use lower case for flexibility
                logger.debug(f"ALTER TASK: Checking Tree node '{node_data}' at index {i}")
                # Adjust these clause names based on your actual grammar
                if child.children[0].type == 'ADD':
                    action_type = "ADD_AFTER"
                    action_node = child # Store the clause Tree node
                    break
                elif child.children[0].type == 'REMOVE':
                    action_type = "REMOVE_AFTER"
                    action_node = child # Store the clause Tree node
                    break
                elif child.children[0].type == 'SET': # e.g., set_clause, alter_task_set
                     action_type = "SET"
                     action_node = child # Store the clause Tree node
                     break
                # Add checks for suspend/resume if they can be inside Trees

        logger.debug(f"ALTER TASK: Determined action_type='{action_type}'")

        # --- Now process based on the determined action ---

        if action_type == "SUSPEND":
            if task_name and action_node:
                 self._record_object_reference(task_name, "TASK", "SUSPEND", action_node)
        elif action_type == "RESUME":
             if task_name and action_node:
                 self._record_object_reference(task_name, "TASK", "RESUME", action_node)
        elif action_type == "SET":
            # Search for WAREHOUSE = qualified_name within the action_node
            # (action_node could be the SET token or a set_clause Tree)
            search_root = action_node if isinstance(action_node, Tree) else tree # Search tree if SET was just a token
            warehouse_token = None
            wh_name_node = None
            # Find WAREHOUSE token first within the relevant scope
            # Use find_data for potentially nested structures
            warehouse_nodes = list(search_root.find_data(lambda n: isinstance(n, Token) and n.type == 'WAREHOUSE'))
            if warehouse_nodes:
                warehouse_token = warehouse_nodes[0] # Use the first WAREHOUSE token found
                # Now look for the qualified_name associated with this WAREHOUSE
                # Assume structure like WAREHOUSE -> EQ -> qualified_name or nested within a parent
                # Let's search within the search_root again for simplicity, looking for QN
                # A more robust approach might inspect siblings/parents of warehouse_token if grammar is complex
                wh_name_node = self._find_first_child_by_name(search_root, 'qualified_name') 
                # Crude fallback: find *any* qualified_name if specific search fails
                if not wh_name_node:
                     wh_name_node = next(search_root.find_data('qualified_name'), None)

            if warehouse_token and wh_name_node:
                 wh_name = self._extract_qualified_name(wh_name_node)
                 wh_token_for_loc = next((t for t in wh_name_node.children if isinstance(t, Token)), warehouse_token) # Use QN token if possible
                 if wh_name and task_name:
                     logger.debug(f"Recording SET WAREHOUSE dependency: {task_name} -> {wh_name}")
                     self.engine.result.add_dependency("TASK", task_name, "WAREHOUSE", wh_name, "SET_WAREHOUSE")
                     self._record_object_reference(wh_name, "WAREHOUSE", "REFERENCE", wh_token_for_loc)
            else:
                 logger.warning(f"ALTER TASK SET: Could not reliably find WAREHOUSE token and associated qualified_name within {getattr(search_root, 'data', 'main tree')}.")

        elif action_type in ("ADD_AFTER", "REMOVE_AFTER"):
            dependency_action = "ADDED_AFTER" if action_type == "ADD_AFTER" else "REMOVED_AFTER"
            logger.info(f"Processing {dependency_action} dependencies for task {task_name}")

            dependency_nodes = []
            # Where to search for dependencies depends on whether action_node is the AFTER token or a clause Tree
            search_root_for_deps = None
            if isinstance(action_node, Token) and action_node.type == 'AFTER':
                 # Search in nodes following the AFTER token in the main tree
                 if after_token_index != -1 and after_token_index + 1 < len(tree.children):
                      search_root_for_deps = tree.children[after_token_index + 1]
                 else:
                      logger.warning(f"ALTER TASK {dependency_action}: AFTER token found, but no subsequent node to search.")
            elif isinstance(action_node, Tree):
                 # Search within the clause Tree node itself
                 search_root_for_deps = action_node

            if search_root_for_deps:
                 logger.debug(f"ALTER TASK {dependency_action}: Searching for dependencies within/after node: {getattr(search_root_for_deps, 'data', type(search_root_for_deps))}")
                 # Find all qualified names within the determined scope
                 if isinstance(search_root_for_deps, Tree) and search_root_for_deps.data == 'qualified_name':
                      dependency_nodes.append(search_root_for_deps) # It's a single QN
                 elif isinstance(search_root_for_deps, Tree):
                      dependency_nodes.extend(list(search_root_for_deps.find_data('qualified_name')))
                 else:
                      logger.warning(f"ALTER TASK {dependency_action}: Search root for dependencies is not a Tree: {type(search_root_for_deps)}")

            # --- Process the found dependency nodes --- 
            processed_nodes = set() # Use a set to store (Tree object id, extracted name) tuples for unique check
            unique_dependency_nodes_info = [] # Store tuples of (qn_node, dep_task_name)

            if not dependency_nodes:
                # Log was likely already generated above if action_token_index was valid
                pass 
            else:
                # Log the names extracted for debugging
                extracted_names = [self._extract_qualified_name(n) for n in dependency_nodes if isinstance(n, Tree) and n.data == 'qualified_name']
                logger.debug(f"Qualified names extracted after {dependency_action}: {extracted_names}")

            for qn_node in dependency_nodes:
                # Ensure it's a valid Tree node before extraction
                if isinstance(qn_node, Tree) and qn_node.data == 'qualified_name':
                    dep_task_name = self._extract_qualified_name(qn_node)
                    if dep_task_name:
                        node_id = id(qn_node) # Use object ID for uniqueness check
                        # Check uniqueness based on (node object, extracted name) tuple
                        if (node_id, dep_task_name) not in processed_nodes:
                            unique_dependency_nodes_info.append((qn_node, dep_task_name))
                            processed_nodes.add((node_id, dep_task_name))
                        else:
                            # This should ideally not happen often with the new logic if find_data returns unique nodes
                            logger.debug(f"Skipping duplicate dependency node during processing: {dep_task_name}") 
                    else:
                        logger.warning(f"Could not extract dependency task name from node {qn_node.pretty()}")
                else:
                    # Log if find_data returned something unexpected (e.g., a Token)
                    logger.warning(f"Skipping non-qualified_name node found in dependency list: {type(qn_node)}")

            # Record the unique dependencies found
            if not unique_dependency_nodes_info:
                # Check if the warning was already logged above
                if dependency_nodes: # Only log if we had potential nodes but failed to process/extract names
                    logger.warning(f"Failed to extract valid names from potential dependency nodes after {dependency_action}.")

            for qn_node, dep_task_name in unique_dependency_nodes_info:
                if task_name: # Ensure we have the primary task name
                    if dep_task_name != task_name:
                        logger.debug(f"Recording {dependency_action} dependency: {task_name} -> {dep_task_name}")
                        self.engine.result.add_dependency("TASK", task_name, "TASK", dep_task_name, dependency_action)
                    else:
                        logger.debug(f"Skipping self-dependency {dependency_action} for task: {task_name}")
                else:
                    logger.warning(f"Could not record {dependency_action} dependency for {dep_task_name} as main task_name is missing.")

    def merge_stmt(self, tree: Tree):
        """Visits `merge_stmt` nodes. Extracts target table, source references, and specific target actions.

        Identifies the target table and records MERGE, INSERT, UPDATE, DELETE actions
        on the target based on the presence of corresponding clauses.
        Identifies the source table/subquery in the USING clause and records references.
        Relies on recursive visit for subqueries and other clauses.
        Also marks the MERGE statement as destructive.
        """
        self._debug_tree(tree, "Merge Statement")

        target_table_name = None
        target_table_node = None
        target_token = None
        source_table_node = None  # Holds the qualified_name node if source is a table
        source_subquery_node = None # Holds the select_stmt node if source is a subquery
        source_container_node = None # Holds the node containing the source (e.g., merge_source)

        # --- 1. Find Target Table --- 
        # Assumes target is the first qualified_name after the INTO token.
        merge_into_found = False
        for child in tree.children:
            if isinstance(child, Token) and child.type == 'INTO':
                merge_into_found = True
            elif merge_into_found and isinstance(child, Tree) and child.data == 'qualified_name':
                target_table_node = child
                target_table_name = self._extract_qualified_name(target_table_node)
                target_token = next((t for t in target_table_node.children if isinstance(t, Token)), None)
                break # Found the target

        if not target_table_name or not target_token:
             logger.error(f"MERGE Visitor: Failed to find target table name or token in {tree.pretty()}. Skipping detailed analysis.")
             # Still record base counts even if parsing fails
             self.engine.record_statement("MERGE", tree, self.current_file)
             self.engine.record_destructive_statement("MERGE", tree, self.current_file)
             # Attempt to visit children anyway for potential nested statements
             for child in tree.children:
                 if isinstance(child, Tree):
                     self.visit(child)
             return

        logger.debug(f"MERGE Visitor: Found target table: {target_table_name}")
        # Record the basic MERGE action on the target table immediately
        self._record_object_reference(target_table_name, "TABLE", "MERGE", target_token)

        # --- 2. Find Source (Table or Subquery) --- 
        # Find the node representing the source (e.g., 'merge_source') - adjust name based on grammar
        # Common patterns: USING table_name, USING (subquery)
        # Let's assume the grammar provides a node like 'merge_source' or the source is directly
        # a qualified_name or select_stmt after the USING token/clause.
        using_token_index = -1
        for i, child in enumerate(tree.children):
            if isinstance(child, Token) and child.type == 'USING':
                using_token_index = i
                break
            
        if using_token_index != -1 and using_token_index + 1 < len(tree.children):
            potential_source_container = tree.children[using_token_index + 1]
            if isinstance(potential_source_container, Tree):
                source_container_node = potential_source_container
                # Check if the container itself is the source QN or SELECT
                if source_container_node.data == 'qualified_name':
                    source_table_node = source_container_node
                elif source_container_node.data == 'select_stmt':
                    source_subquery_node = source_container_node
                else:
                    # Look inside the container node
                    source_table_node = self._find_first_child_by_name(source_container_node, 'qualified_name')
                    source_subquery_node = self._find_first_child_by_name(source_container_node, 'select_stmt')
            else:
                logger.warning(f"MERGE Visitor: Node after USING is not a Tree: {potential_source_container}")
                
        # Process the found source
        if source_table_node:
            source_name = self._extract_qualified_name(source_table_node)
            source_token = next((t for t in source_table_node.children if isinstance(t, Token)), None)
            if source_name and source_token:
                logger.debug(f"MERGE Visitor: Found source table: {source_name}")
                # Record reference to the source table (using SELECT action for consistency/tests)
                self._record_object_reference(source_name, "TABLE", "SELECT", source_token)
            else:
                logger.warning(f"MERGE Visitor: Failed to extract name/token from source qualified_name: {source_table_node.pretty()}")
        elif source_subquery_node:
            logger.debug(f"MERGE Visitor: Found source subquery (select_stmt). Will rely on recursion.")
        else:
            logger.warning(f"MERGE Visitor: Could not determine source type (table/subquery) after USING keyword.")

        # --- 3. Check for Target Action Clauses --- 
        # Use find_data which searches recursively across the whole merge statement.
        has_update = any(tree.find_data('merge_update_clause'))
        has_delete = any(tree.find_data('merge_delete_clause'))
        has_insert = any(tree.find_data('merge_insert_clause'))

        # Record specific actions found on the target table
        if has_insert:
            logger.debug(f"MERGE Visitor: Recording INSERT action on {target_table_name}")
            self._record_object_reference(target_table_name, "TABLE", "INSERT", target_token)
        if has_update:
            logger.debug(f"MERGE Visitor: Recording UPDATE action on {target_table_name}")
            self._record_object_reference(target_table_name, "TABLE", "UPDATE", target_token)
        if has_delete:
            logger.debug(f"MERGE Visitor: Recording DELETE action on {target_table_name}")
            self._record_object_reference(target_table_name, "TABLE", "DELETE", target_token)

        # --- 4. Final Recording --- 
        self.engine.record_statement("MERGE", tree, self.current_file)
        self.engine.record_destructive_statement("MERGE", tree, self.current_file)

        # --- 5. Recurse into relevant children --- 
        # We need to visit clauses like ON, WHEN MATCHED/NOT MATCHED, 
        # and the source subquery node (if source was a subquery).
        # Avoid re-visiting the top-level target table node and the source container node 
        # *unless* the source container was the subquery itself.
        nodes_to_visit = []
        nodes_to_skip_explicitly = {target_table_node} 
        
        # If source was a table, skip its container too (unless container is the merge_stmt itself)
        if source_table_node and source_container_node and source_container_node is not tree:
            nodes_to_skip_explicitly.add(source_container_node)
        
        for child in tree.children:
            if isinstance(child, Tree) and child not in nodes_to_skip_explicitly:
                # Ensure we visit the source subquery if it exists and wasn't skipped
                if child == source_subquery_node or child == source_container_node and source_subquery_node:
                     nodes_to_visit.append(child) 
                # Add other necessary clauses (ON, WHEN) if they are direct children
                # Adjust based on actual grammar node names (e.g., 'merge_on_clause', 'merge_when_clause')
                elif child.data in ('merge_on_clause', 'merge_when_clause', 'merge_update_clause', 'merge_delete_clause', 'merge_insert_clause'):
                     nodes_to_visit.append(child)
                # Only add the source container if it wasn't explicitly skipped and contains the subquery we need to visit
                elif child == source_container_node and source_subquery_node:
                     nodes_to_visit.append(child)
                 
        # Deduplicate nodes_to_visit just in case
        final_nodes_to_visit = []
        seen_ids = set()
        for node in nodes_to_visit:
            if id(node) not in seen_ids:
                 final_nodes_to_visit.append(node)
                 seen_ids.add(id(node))

        logger.debug(f"MERGE Visitor: Starting recursion. Nodes to visit explicitly: {[getattr(n, 'data', type(n)) for n in final_nodes_to_visit]}")
        for node in final_nodes_to_visit:
             logger.debug(f"MERGE Visitor: Visiting child node: {getattr(node, 'data', type(node))}")
             self.visit(node)

    def truncate_stmt(self, tree: Tree):
        """Visits `truncate_stmt` nodes. Extracts table references.

        Identifies tables targeted by TRUNCATE statements.
        Records found objects as 'TRUNCATE'.
        Also ensures the destructive statement is recorded.
        """
        self._debug_tree(tree, "Truncate Statement")
        
        # Find the table name in TRUNCATE TABLE clause
        table_ref = self._find_first_child_by_name(tree, 'qualified_name')
        
        if table_ref:
            table_name = self._extract_qualified_name(table_ref)
            first_token = next((t for t in table_ref.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found table targeted by TRUNCATE: {table_name}")
                self._record_object_reference(table_name, "TABLE", "TRUNCATE", first_token)
                
                # Make sure to record the TRUNCATE_TABLE destructive statement
                self.engine.record_destructive_statement("TRUNCATE_TABLE", tree, self.current_file)

    def alter_table_set_masking_policy_stmt(self, tree: Tree):
        """Visits `alter_table_set_masking_policy_stmt` nodes. Extracts the table name, column name, and policy name."""
        self._debug_tree(tree, "Alter Table Set Masking Policy Statement")

        table_name_node = None
        column_token = None
        policy_name_node = None

        # More robust extraction logic:
        all_q_nodes = list(tree.find_data('qualified_name')) # Find all qualified_name nodes recursively
        all_tokens = [child for child in tree.children if isinstance(child, Token)] # Get direct token children

        # Table name is likely the first qualified_name
        if all_q_nodes:
            table_name_node = all_q_nodes[0]

        # Find column IDENTIFIER after MODIFY -> COLUMN sequence
        modify_found = False
        column_found = False
        for token in all_tokens:
            if token.type == 'MODIFY':
                modify_found = True
                column_found = False # Reset in case of multiple MODIFY
                continue
            if modify_found and token.type == 'COLUMN':
                column_found = True
                continue
            if column_found and token.type == 'IDENTIFIER':
                column_token = token
                break # Found the first IDENTIFIER after MODIFY COLUMN

        # Policy name is likely the second qualified_name
        if len(all_q_nodes) >= 2:
            # Ensure the second q_node isn't part of the first one (e.g., db.schema.table)
            if all_q_nodes[1] not in all_q_nodes[0].find_data('qualified_name'):
                 policy_name_node = all_q_nodes[1]
            elif len(all_q_nodes) >= 3: # Maybe it's the third if the first had multiple parts?
                 policy_name_node = all_q_nodes[2] # This is getting heuristic

        # Extract names and record actions
        if table_name_node and column_token and policy_name_node:
            table_name = self._extract_qualified_name(table_name_node)
            first_token = next((t for t in table_name_node.children if isinstance(t, Token)), None)
            if table_name and first_token:
                logger.debug(f"Found table {table_name}")
                self._record_object_reference(table_name, "TABLE", "ALTER", first_token)

            # Correctly get column name from token value and record with COLUMN type
            column_name = column_token.value
            if column_name:
                logger.info(f"VISITOR: Attempting to record COLUMN object: Name='{column_name}', Type='COLUMN', Action='SET_MASKING_POLICY'") # <<< Add logging HERE
                logger.debug(f"Found column {column_name}")
                self._record_object_reference(column_name, "COLUMN", "SET_MASKING_POLICY", column_token)

            # Correctly get policy token and record policy reference
            policy_name = self._extract_qualified_name(policy_name_node)
            actual_policy_token = next((t for t in policy_name_node.children if isinstance(t, Token)), None)
            if policy_name and actual_policy_token:
                logger.debug(f"Found policy {policy_name}")
                # Record policy with SET_MASKING_POLICY action, as expected by test
                self._record_object_reference(policy_name, "MASKING_POLICY", "SET_MASKING_POLICY", actual_policy_token)
            elif policy_name: # Fallback if token extraction fails
                logger.warning(f"Could not extract token from policy node for {policy_name}, using node itself.")
                self._record_object_reference(policy_name, "MASKING_POLICY", "SET_MASKING_POLICY", policy_name_node) # Also use correct action here

            # Record the specific statement count
            self.engine.record_statement("SET_MASKING_POLICY", tree, self.current_file)
        else:
            logger.warning("Failed to extract all names/tokens in alter_table_set_masking_policy_stmt")

    def execute_task_stmt(self, tree: Tree):
        """Visits `execute_task_stmt` nodes. Extracts the task name and records EXECUTE_TASK action."""
        self._debug_tree(tree, "Execute Task Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            task_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if task_name and first_token:
                self._record_object_reference(task_name, "TASK", "EXECUTE_TASK", first_token)
                self.engine.record_statement("EXECUTE_TASK", tree, self.current_file)

    def call_procedure_stmt(self, tree: Tree):
        """Visits `call_procedure_stmt` nodes. Extracts the procedure name and records CALL action."""
        self._debug_tree(tree, "Call Procedure Statement")
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            proc_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if proc_name and first_token:
                logger.debug(f"Found procedure CALL: {proc_name}")
                # Record the CALL action on the PROCEDURE object
                self._record_object_reference(proc_name, "PROCEDURE", "CALL", first_token)
                # Explicitly record the statement count
                self.engine.record_statement("CALL", tree, self.current_file)
            else:
                logger.warning(f"CALL statement: Could not extract procedure name or token from {qual_name_node.pretty()}")
        else:
             logger.warning(f"Could not find qualified_name node in CALL statement: {tree.pretty()}")
        
        # Recursively visit arguments if needed (e.g., if arguments can contain subqueries)
        # Find the expr_list node (adjust data name based on grammar if different)
        arg_list_node = self._find_first_child_by_name(tree, 'expr_list')
        if arg_list_node:
            self.visit(arg_list_node)

    def create_schema_stmt(self, tree: Tree):
        """Visits `create_schema_stmt` nodes. Extracts the `qualified_name` of the schema and handles CLONE."""
        self._debug_tree(tree, "Create Schema Statement")
        # Record schema creation
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        if qual_name_node:
            schema_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            if schema_name and first_token:
                logger.debug(f"Found schema creation: {schema_name}")
                self._record_object_reference(schema_name, "SCHEMA", "CREATE", first_token)
                # Record the CREATE_SCHEMA statement count
                self.engine.record_statement("CREATE_SCHEMA", tree, self.current_file)
        # Record CLONE source schemas
        for clone in tree.find_data('clone_clause'):
            qn = self._find_first_child_by_name(clone, 'qualified_name')
            if qn:
                source = self._extract_qualified_name(qn)
                tok = next((t for t in qn.children if isinstance(t, Token)), None)
                if source and tok:
                    self._record_object_reference(source, "SCHEMA", "CLONE", tok)

    def drop_share_stmt(self, tree: Tree):
        """Visits `drop_share_stmt` nodes. Extracts the share being dropped.

        Identifies the share object being dropped.
        Records found objects under 'DROP_SHARE' action.
        Also ensures the destructive statement is recorded.
        """
        self._debug_tree(tree, "Drop Share Statement")
        
        # Find qualified_name node for share name
        qual_name_node = self._find_first_child_by_name(tree, 'qualified_name')
        
        if qual_name_node:
            share_name = self._extract_qualified_name(qual_name_node)
            first_token = next((t for t in qual_name_node.children if isinstance(t, Token)), None)
            
            if share_name and first_token:
                logger.debug(f"Found share to drop: {share_name}")
                # Record the object reference with action "DROP_SHARE" instead of "DROP"
                self._record_object_reference(share_name, "SHARE", "DROP_SHARE", first_token)
                
                # Record the specific DROP_SHARE statement
                self.engine.record_statement("DROP_SHARE", tree, self.current_file)
                
                # Record it as a destructive statement
                self.engine.record_destructive_statement("DROP_SHARE", tree, self.current_file)
            else:
                logger.warning(f"Could not extract share name from DROP SHARE statement")
                # Default to generic DROP statement
                self.engine.record_destructive_statement("DROP", tree, self.current_file)
